{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/AdvGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEAezPmkWmdh",
        "colab_type": "text"
      },
      "source": [
        "From author ctargon:\n",
        "\n",
        "Create a './weights' directory as well as subdirectories './weights/generator, ./weights/discriminator, ./weights/target_model' to contain the saved weights for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGt0_bz_Viby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Github author: ctargon https://github.com/ctargon/AdvGAN-tf/blob/master/AdvGAN.py\n",
        "\n",
        "#First train the generator, specifiy whether or not you want it to be targeted\n",
        "#Different generator will be trained for each target\n",
        "#After training, call \"attack\" to load weights from generator and run attack on test set\n",
        "#print out before and after picture of two images from last batch\n",
        "'''\n",
        "\tAdvGAN architecture\n",
        "\tref: https://arxiv.org/pdf/1801.02610.pdf\n",
        "'''\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os, sys\n",
        "import random\n",
        "\n",
        "#make sure GAN_setup.py is in connected folder\n",
        "from GAN_setup import generator, discriminator\n",
        "\n",
        "#ctargon created class Target and defined/trained his target model in there, then called here\n",
        "#from target_models import Target as target_model\n",
        "\n",
        "# randomly shuffle a dataset \n",
        "def shuffle(X, Y):\n",
        "\trands = random.sample(range(X.shape[0]),X.shape[0])\n",
        "\treturn X[rands], Y[rands]\n",
        "\n",
        "# get the next batch based on x, y, and the iteration (based on batch_size)\n",
        "def next_batch(X, Y, i, batch_size):\n",
        "\tidx = i * batch_size\n",
        "\tidx_n = i * batch_size + batch_size\n",
        "\treturn X[idx:idx_n], Y[idx:idx_n]\n",
        "\n",
        "# loss function to encourage misclassification after perturbation\n",
        "def adv_loss(preds, labels, is_targeted):\n",
        "\treal = tf.reduce_sum(labels * preds, 1)\n",
        "\tother = tf.reduce_max((1 - labels) * preds - (labels * 10000), 1)\n",
        "\tif is_targeted:\n",
        "\t\treturn tf.reduce_sum(tf.maximum(0.0, other - real))\n",
        "\treturn tf.reduce_sum(tf.maximum(0.0, real - other))\n",
        "\n",
        "# loss function to influence the perturbation to be as close to 0 as possible\n",
        "def perturb_loss(preds, thresh=0.3):\n",
        "\tzeros = tf.zeros((tf.shape(preds)[0]))\n",
        "\treturn tf.reduce_mean(tf.maximum(zeros, tf.norm(tf.reshape(preds, (tf.shape(preds)[0], -1)), axis=1) - thresh))\n",
        "\n",
        "\n",
        "# function that defines ops, graphs, and training procedure for AdvGAN framework\n",
        "def AdvGAN(X, y, X_test, y_test, epochs=50, batch_size=128, target=-1):\n",
        "\t# placeholder definitions\n",
        "\tx_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "\tt = tf.placeholder(tf.float32, [None, y.shape[-1]]) # target placeholder\n",
        "\tis_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "\t#-----------------------------------------------------------------------------------\n",
        "\t# MODEL DEFINITIONS\n",
        "\tis_targeted = False\n",
        "\tif target in range(0, y.shape[-1]):\n",
        "\t\tis_targeted = True\n",
        "\n",
        "\t# gather target model\n",
        "\tf = target_model()\n",
        "\n",
        "\tthresh = 0.3\n",
        "\n",
        "\t# generate perturbation, add to original input image(s)\n",
        "\tperturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "\tx_perturbed = perturb + x_pl\n",
        "\tx_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "\n",
        "\t# pass real and perturbed image to discriminator and the target model\n",
        "\td_real_logits, d_real_probs = discriminator(x_pl, is_training)\n",
        "\td_fake_logits, d_fake_probs = discriminator(x_perturbed, is_training)\n",
        "\t\n",
        "\t# pass real and perturbed images to the model we are trying to fool\n",
        "\tf_real_logits, f_real_probs = f.ModelC(x_pl)\n",
        "\tf_fake_logits, f_fake_probs = f.ModelC(x_perturbed)\n",
        "\n",
        "\t\n",
        "\t# generate labels for discriminator (optionally smooth labels for stability)\n",
        "\tsmooth = 0.0\n",
        "\td_labels_real = tf.ones_like(d_real_probs) * (1 - smooth)\n",
        "\td_labels_fake = tf.zeros_like(d_fake_probs)\n",
        "\n",
        "\t#-----------------------------------------------------------------------------------\n",
        "\t# LOSS DEFINITIONS\n",
        "\t# discriminator loss\n",
        "\td_loss_real = tf.losses.mean_squared_error(predictions=d_real_probs, labels=d_labels_real)\n",
        "\td_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=d_labels_fake)\n",
        "\td_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "\t# generator loss\n",
        "\tg_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=tf.ones_like(d_fake_probs))\n",
        "\n",
        "\t# perturbation loss (minimize overall perturbation)\n",
        "\tl_perturb = perturb_loss(perturb, thresh)\n",
        "\n",
        "\t# adversarial loss (encourage misclassification)\n",
        "\tl_adv = adv_loss(f_fake_probs, t, is_targeted)\n",
        "\n",
        "\t# weights for generator loss function\n",
        "\talpha = 1.0\n",
        "\tbeta = 5.0\n",
        "\tg_loss = l_adv + alpha*g_loss_fake + beta*l_perturb \n",
        "\n",
        "\t# ----------------------------------------------------------------------------------\n",
        "\t# gather variables for training/restoring\n",
        "\tt_vars = tf.trainable_variables()\n",
        "\tf_vars = [var for var in t_vars if 'ModelC' in var.name]\n",
        "\td_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "\tg_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "\t# define optimizers for discriminator and generator\n",
        "\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\twith tf.control_dependencies(update_ops):\n",
        "\t\td_opt = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n",
        "\t\tg_opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "\t# create saver objects for the target model, generator, and discriminator\n",
        "\tsaver = tf.train.Saver(f_vars)\n",
        "\tg_saver = tf.train.Saver(g_vars)\n",
        "\td_saver = tf.train.Saver(d_vars)\n",
        "\n",
        "\tinit  = tf.global_variables_initializer()\n",
        "\n",
        "\tsess  = tf.Session()\n",
        "\tsess.run(init)\n",
        "\n",
        "\t# load the pretrained target model\n",
        "\ttry:\n",
        "\t\tsaver.restore(sess, \"./weights/target_model/model.ckpt\")\n",
        "\texcept:\n",
        "\t\tprint(\"make sure to train the target model first...\")\n",
        "\t\tsys.exit(1)\n",
        "\n",
        "\ttotal_batches = int(X.shape[0] / batch_size)\n",
        "\n",
        "\tfor epoch in range(0, epochs):\n",
        "\n",
        "\t\tX, y = shuffle(X, y)\n",
        "\t\tloss_D_sum = 0.0\n",
        "\t\tloss_G_fake_sum = 0.0\n",
        "\t\tloss_perturb_sum = 0.0\n",
        "\t\tloss_adv_sum = 0.0\n",
        "\n",
        "\t\tfor i in range(total_batches):\n",
        "\n",
        "\t\t\tbatch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "\t\t\t# if targeted, create one hot vectors of the target\n",
        "\t\t\tif is_targeted:\n",
        "\t\t\t\ttargets = np.full((batch_y.shape[0],), target)\n",
        "\t\t\t\tbatch_y = np.eye(y.shape[-1])[targets]\n",
        "\n",
        "\t\t\t# train the discriminator first n times\n",
        "\t\t\tfor _ in range(1):\n",
        "\t\t\t\t_, loss_D_batch = sess.run([d_opt, d_loss], feed_dict={x_pl: batch_x, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   is_training: True})\n",
        "\n",
        "\t\t\t# train the generator n times\n",
        "\t\t\tfor _ in range(1):\n",
        "\t\t\t\t_, loss_G_fake_batch, loss_adv_batch, loss_perturb_batch = \\\n",
        "\t\t\t\t\t\t\t\t\tsess.run([g_opt, g_loss_fake, l_adv, l_perturb], \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfeed_dict={x_pl: batch_x, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   t: batch_y, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   is_training: True})\n",
        "\t\t\tloss_D_sum += loss_D_batch\n",
        "\t\t\tloss_G_fake_sum += loss_G_fake_batch\n",
        "\t\t\tloss_perturb_sum += loss_perturb_batch\n",
        "\t\t\tloss_adv_sum += loss_adv_batch\n",
        "\n",
        "\t\tprint(\"epoch %d:\\nloss_D: %.3f, loss_G_fake: %.3f, \\\n",
        "\t\t\t\t\\nloss_perturb: %.3f, loss_adv: %.3f, \\n\" %\n",
        "\t\t\t\t(epoch + 1, loss_D_sum/total_batches, loss_G_fake_sum/total_batches,\n",
        "\t\t\t\tloss_perturb_sum/total_batches, loss_adv_sum/total_batches))\n",
        "\n",
        "\t\tif epoch % 10 == 0:\n",
        "\t\t\tg_saver.save(sess, \"weights/generator/gen.ckpt\")\n",
        "\t\t\td_saver.save(sess, \"weights/discriminator/disc.ckpt\")\n",
        "\n",
        "\t# evaluate the test set\n",
        "\tcorrect_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\taccs = []\n",
        "\ttotal_batches_test = int(X_test.shape[0] / batch_size)\n",
        "\tfor i in range(total_batches_test):\n",
        "\t\tbatch_x, batch_y = next_batch(X_test, y_test, i, batch_size)\n",
        "\t\tacc, x_pert = sess.run([accuracy, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "\t\taccs.append(acc)\n",
        "\n",
        "\tprint('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "\n",
        "\t# plot some images and their perturbed counterparts\n",
        "\tf, axarr = plt.subplots(2,2)\n",
        "\taxarr[0,0].imshow(np.squeeze(batch_x[2]), cmap='Greys_r')\n",
        "\taxarr[0,1].imshow(np.squeeze(x_pert[2]), cmap='Greys_r')\n",
        "\taxarr[1,0].imshow(np.squeeze(batch_x[5]), cmap='Greys_r')\n",
        "\taxarr[1,1].imshow(np.squeeze(x_pert[5]), cmap='Greys_r')\n",
        "\tplt.show()\n",
        "\n",
        "\tprint('finished training, saving weights')\n",
        "\tg_saver.save(sess, \"weights/generator/gen.ckpt\")\n",
        "\td_saver.save(sess, \"weights/discriminator/disc.ckpt\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def attack(X, y, batch_size=128, thresh=0.3, target=-1):\n",
        "\tx_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "\tt = tf.placeholder(tf.float32, [None, 10]) # target placeholder\n",
        "\tis_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "\tis_targeted = False\n",
        "\tif target in range(0, y.shape[-1]):\n",
        "\t\tis_targeted = True\n",
        "\n",
        "\tperturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "\tx_perturbed = perturb + x_pl\n",
        "\tx_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "\n",
        "\tf = target_model()\n",
        "\tf_real_logits, f_real_probs = f.ModelC(x_pl)\n",
        "\tf_fake_logits, f_fake_probs = f.ModelC(x_perturbed)\n",
        "\n",
        "\tt_vars = tf.trainable_variables()\n",
        "\tf_vars = [var for var in t_vars if 'ModelC' in var.name]\n",
        "\tg_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "\tsess = tf.Session()\n",
        "\n",
        "\tf_saver = tf.train.Saver(f_vars)\n",
        "\tg_saver = tf.train.Saver(g_vars)\n",
        "\tf_saver.restore(sess, \"./weights/target_model/model.ckpt\")\n",
        "\tg_saver.restore(sess, tf.train.latest_checkpoint(\"./weights/generator/\"))\n",
        "\n",
        "\trawpert, pert, fake_l, real_l = sess.run([perturb, x_perturbed, f_fake_probs, f_real_probs], \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfeed_dict={x_pl: X[:32], \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   is_training: False})\n",
        "\tprint('LA: ' + str(np.argmax(y[:32], axis=1)))\n",
        "\tprint('OG: ' + str(np.argmax(real_l, axis=1)))\n",
        "\tprint('PB: ' + str(np.argmax(fake_l, axis=1)))\n",
        "\n",
        "\tcorrect_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\taccs = []\n",
        "\ttotal_batches_test = int(X.shape[0] / batch_size)\n",
        "\tfor i in range(total_batches_test):\n",
        "\t\tbatch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "\t\tif is_targeted:\n",
        "\t\t\ttargets = np.full((batch_y.shape[0],), target)\n",
        "\t\t\tbatch_y = np.eye(y.shape[-1])[targets]\n",
        "\n",
        "\t\tacc, fake_l, x_pert = sess.run([accuracy, f_fake_probs, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "\t\taccs.append(acc)\n",
        "\n",
        "\tprint('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "\n",
        "\tf, axarr = plt.subplots(2,2)\n",
        "\taxarr[0,0].imshow(np.squeeze(X[3]), cmap='Greys_r')\n",
        "\taxarr[0,1].imshow(np.squeeze(pert[3]), cmap='Greys_r')\n",
        "\taxarr[1,0].imshow(np.squeeze(X[4]), cmap='Greys_r')\n",
        "\taxarr[1,1].imshow(np.squeeze(pert[4]), cmap='Greys_r')\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# read in mnist data\n",
        "(X,y), (X_test,y_test) = mnist.load_data()\n",
        "# (X, y), (X_test, y_test) = cifar10.load_data()\n",
        "X = np.divide(X, 255.0)\n",
        "X_test = np.divide(X_test, 255.0)\n",
        "X = X.reshape(X.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "y = to_categorical(y, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "AdvGAN(X, y, X_test, y_test, batch_size=128, epochs=50, target=-1)\n",
        "attack(X_test, y_test, target=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mark2_TSFClassifier_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/Mark2_44_TSFClassifier_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isD9mtH373R4",
        "colab_type": "text"
      },
      "source": [
        "Author: Stephanie Tietz\n",
        "\n",
        "LeNet5 model design and grayscale preprocessing idea from: mohamedameen93 on full German Traffic Sign dataset\n",
        "\n",
        "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow\n",
        "\n",
        "Regularization options provided, Adadelta or Adam optimizer, trained on German TS Dataset plus \"not a sign\" images, optimized for 3 classes first then expanding to 44\n",
        "\n",
        "Multiclass Image Classification in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc_cvQN_70HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d6e4bfa-c595-4cb5-d63d-aa2eaa568b62"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1187) #to help reproduce\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "#import random\n",
        "#import cv2\n",
        "#from skimage.filters import rank\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "#from keras.utils import np_utils\n",
        "#from keras import backend as K\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5l_XxOH8Lgz",
        "colab_type": "code",
        "outputId": "6bf909dc-9634-4ede-b182-cd55f6f5369c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#upload data\n",
        "#from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#traindata = np.load('smalltrain.npy') #only 3 classes, both circle signs\n",
        "traindata = np.load('alltrain.npy') #all classes\n",
        "\n",
        "#testdata = np.load('smalltest.npy')\n",
        "testdata = np.load('alltest.npy')\n",
        "\n",
        "#validdata = np.load('allvalid.npy')\n",
        "'''\n",
        "import pickle\n",
        "\n",
        "\n",
        "training_file = 'train.p'\n",
        "testing_file = 'test.p'\n",
        "validation_file = 'valid.p'\n",
        "\n",
        "with open(training_file, mode='rb') as f:\n",
        "    tstrain = pickle.load(f)\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    tstest = pickle.load(f)\n",
        "with open(validation_file, mode='rb') as f:\n",
        "    tsvalid = pickle.load(f)\n",
        "    '''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport pickle\\n\\n\\ntraining_file = 'train.p'\\ntesting_file = 'test.p'\\nvalidation_file = 'valid.p'\\n\\nwith open(training_file, mode='rb') as f:\\n    tstrain = pickle.load(f)\\nwith open(testing_file, mode='rb') as f:\\n    tstest = pickle.load(f)\\nwith open(validation_file, mode='rb') as f:\\n    tsvalid = pickle.load(f)\\n    \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TskHKwV0zO21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "63dfcb72-09d5-4935-ce64-baf64062dd9c"
      },
      "source": [
        "'''\n",
        "X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "num_train = X_train.shape[0]\n",
        "num_test = X_test.shape[0]\n",
        "num_valid = X_valid.shape[0]\n",
        "'''\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX_train, Y_train = tstrain['features'], tstrain['labels']\\nX_valid, Y_valid = tsvalid['features'], tsvalid['labels']\\nX_test, Y_test = tstest['features'], tstest['labels']\\n\\nnum_train = X_train.shape[0]\\nnum_test = X_test.shape[0]\\nnum_valid = X_valid.shape[0]\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bDJvjGb8geR",
        "colab_type": "code",
        "outputId": "9a0c63e7-b5ca-4f91-a852-902576842cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#traindata = np.load('smalltrain2.npy') #smalltrain2 has triangle sign\n",
        "#testdata = np.load('smalltest2.npy')\n",
        "\n",
        "#traindata = np.load('tsrtrain.npy')\n",
        "#testdata = np.load('tsrtest.npy')\n",
        "\n",
        "print(traindata.shape) #(41109,3073) for all\n",
        "print(testdata.shape) #(13330,3073) for all\n",
        "print(testdata)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41109, 3073)\n",
            "(13330, 3073)\n",
            "[[214 217 218 ... 134 136  43]\n",
            " [123 123 126 ...  51  47  43]\n",
            " [ 98  98  93 ...  99  94  43]\n",
            " ...\n",
            " [ 60 102  38 ...  83  12   6]\n",
            " [237  20 255 ...  41  30   7]\n",
            " [ 18 138  24 ...  22  13  10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppQcdFyMxKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signs = []\n",
        "#with open('signnames.csv', 'r') as csvfile:\n",
        "    #signnames = csv.reader(csvfile, delimiter=',')\n",
        "    #next(signnames,None)\n",
        "    #for row in signnames:\n",
        "     #   signs.append(row[1])\n",
        "    #csvfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMi6286r8tVV",
        "colab_type": "code",
        "outputId": "a3787343-3cc3-4962-b565-c834c38e5037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "#split into x and y\n",
        "X_train = traindata[:,:-1]\n",
        "Y_train = traindata[:,-1]\n",
        "#Y_train = Y_train.reshape(len(Y_train),1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_test = testdata[:,:-1]\n",
        "Y_test = testdata[:,-1]\n",
        "#Y_test = Y_test.reshape(len(Y_test),1)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "#X_valid = validdata[:,:-1]\n",
        "#Y_valid = validdata[:,-1]\n",
        "#Y_valid = Y_valid.reshape(len(Y_valid),1)\n",
        "#print(X_valid.shape)\n",
        "#print(Y_valid.shape)\n",
        "\n",
        "#reshape into (32,32,3) for each example for this model input\n",
        "X_train = (X_train.reshape(traindata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_train.shape)\n",
        "X_test = (X_test.reshape(testdata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_test.shape)\n",
        "#X_valid = (X_valid.reshape(validdata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "#print(X_valid.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41109, 3072)\n",
            "(41109, 1)\n",
            "(13330, 3072)\n",
            "(13330, 1)\n",
            "(41109, 32, 32, 3)\n",
            "(13330, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLk-mamjn4LL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "019c8dc7-8b4a-4531-e2d7-ccc767529129"
      },
      "source": [
        "#START OF DATA PREPROCESSING\n",
        "#Shuffle\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#Randomize (shuffle) the data\n",
        "print(Y_train)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "#X_valid, Y_valid = shuffle(X_valid, Y_valid)\n",
        "#X_test, Y_test = shuffle(X_test, Y_test)\n",
        "print(Y_train)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[43]\n",
            " [43]\n",
            " [43]\n",
            " ...\n",
            " [42]\n",
            " [42]\n",
            " [42]]\n",
            "[[ 1]\n",
            " [16]\n",
            " [15]\n",
            " ...\n",
            " [13]\n",
            " [12]\n",
            " [12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LWatNlVPog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "06af849d-217b-4063-aca1-9214dcb4d109"
      },
      "source": [
        "#Make grayscale\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "#print(X_valid.shape)\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "#X_valid = np.dot(X_valid, grayscale)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "#print(X_valid.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41109, 32, 32, 3)\n",
            "(13330, 32, 32, 3)\n",
            "(41109, 32, 32)\n",
            "(13330, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_P1x9lhSPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b569e4e-852e-42ed-c24f-7f460c2a7b4b"
      },
      "source": [
        "#Normalize data\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "#X_valid = np.array(X_valid)/255\n",
        "print(X_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41109, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjrwooR2fwdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae1dc1b2-26a7-42b8-b011-e1a61dcbd8ad"
      },
      "source": [
        "#Expand dimensions to fit 4D input array\n",
        "\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "print(X_test.shape)\n",
        "\n",
        "#X_valid = np.expand_dims(X_valid,-1)\n",
        "#print(X_valid.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41109, 32, 32, 1)\n",
            "(13330, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_1efCDVRHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute mean image of training set and subtract from training images (not test images)\n",
        "#chann_index_swap = np.swapaxes(X_train,0,3)\n",
        "#mean_image = [[[sum(pixel)/len(pixel) for pixel in col] for col in row] for row in chann_index_swap]\n",
        "#mean_image = np.swapaxes(mean_image,0,2)\n",
        "#mean_image = np.swapaxes(mean_image,0,1)\n",
        "\n",
        "#X_train = X_train - mean_image\n",
        "#print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptTydNb8otG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 44 #change to 44 for alldata\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "\n",
        "#Useful image variables\n",
        "im_rows = 32\n",
        "im_cols = 32\n",
        "image_shape = (32, 32, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAxWJ3R-kR9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "85b7a6e7-a85d-4280-a05d-ff10b2af9c06"
      },
      "source": [
        "#Histogram visualization of classes\n",
        "hist_data = np.histogram(Y_train, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_train, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,2500])\n",
        "plt.show()\n",
        "print(\"Train Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n",
        "'''\n",
        "hist_data = np.histogram(Y_valid, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_valid, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,250])\n",
        "plt.show()\n",
        "print(\"Valid Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n",
        "'''\n",
        "hist_data = np.histogram(Y_test, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_test, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,1000])\n",
        "plt.show()\n",
        "print(\"Test Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSdMhIXpudjIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Class with most examples:\n",
            "2 2250\n",
            "Class with least examples:\n",
            "37 210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0CSOmUASFKnDABJ6tT/A51CyUmIvjsOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test Class with most examples:\n",
            "2 750\n",
            "Class with least examples:\n",
            "41 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gQozorl2wrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet:  \n",
        "\n",
        "    def __init__(self, n_out=44, mu=0, sigma=0.1, learning_rate=0.001):\n",
        "        # Hyperparameters\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "\n",
        "        # Layer 1 (Convolutional): Input = 32x32x1. Output = 28x28x6.\n",
        "        self.filter1_width = 5\n",
        "        self.filter1_height = 5\n",
        "        self.input1_channels = 1\n",
        "        self.conv1_output = 6\n",
        "        # Weight and bias\n",
        "        self.conv1_weight = tf.Variable(tf.truncated_normal(\n",
        "            shape=(self.filter1_width, self.filter1_height, self.input1_channels, self.conv1_output),\n",
        "            mean = self.mu, stddev = self.sigma))\n",
        "        self.conv1_bias = tf.Variable(tf.zeros(self.conv1_output))\n",
        "        # Apply Convolution\n",
        "        self.conv1 = tf.nn.conv2d(x, self.conv1_weight, strides=[1, 1, 1, 1], padding='VALID') + self.conv1_bias\n",
        "        \n",
        "        # Activation:\n",
        "        self.conv1 = tf.nn.relu(self.conv1)\n",
        "        \n",
        "        # Pooling: Input = 28x28x6. Output = 14x14x6.\n",
        "        self.conv1 = tf.nn.max_pool(self.conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "        \n",
        "        # Layer 2 (Convolutional): Output = 10x10x16.\n",
        "        self.filter2_width = 5\n",
        "        self.filter2_height = 5\n",
        "        self.input2_channels = 6\n",
        "        self.conv2_output = 16\n",
        "        # Weight and bias\n",
        "        self.conv2_weight = tf.Variable(tf.truncated_normal(\n",
        "            shape=(self.filter2_width, self.filter2_height, self.input2_channels, self.conv2_output),\n",
        "            mean = self.mu, stddev = self.sigma))\n",
        "        self.conv2_bias = tf.Variable(tf.zeros(self.conv2_output))\n",
        "        # Apply Convolution\n",
        "        self.conv2 = tf.nn.conv2d(self.conv1, self.conv2_weight, strides=[1, 1, 1, 1], padding='VALID') + self.conv2_bias\n",
        "        \n",
        "        # Activation:\n",
        "        self.conv2 = tf.nn.relu(self.conv2)\n",
        "        \n",
        "        # Pooling: Input = 10x10x16. Output = 5x5x16.\n",
        "        self.conv2 = tf.nn.max_pool(self.conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "        \n",
        "        # Flattening: Input = 5x5x16. Output = 400.\n",
        "        self.fully_connected0 = Flatten()(self.conv2)\n",
        "        \n",
        "        # Layer 3 (Fully Connected): Input = 400. Output = 120.\n",
        "        self.connected1_weights = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = self.mu, stddev = self.sigma))\n",
        "        self.connected1_bias = tf.Variable(tf.zeros(120))\n",
        "        self.fully_connected1 = tf.add((tf.matmul(self.fully_connected0, self.connected1_weights)), self.connected1_bias)\n",
        "        \n",
        "        # Activation:\n",
        "        self.fully_connected1 = tf.nn.relu(self.fully_connected1)\n",
        "    \n",
        "        # Layer 4 (Fully Connected): Input = 120. Output = 84.\n",
        "        self.connected2_weights = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = self.mu, stddev = self.sigma))\n",
        "        self.connected2_bias = tf.Variable(tf.zeros(84))\n",
        "        self.fully_connected2 = tf.add((tf.matmul(self.fully_connected1, self.connected2_weights)), self.connected2_bias)\n",
        "        \n",
        "        # Activation.\n",
        "        self.fully_connected2 = tf.nn.relu(self.fully_connected2)\n",
        "    \n",
        "        # Layer 5 (Fully Connected): Input = 84. Output = 44.\n",
        "        self.output_weights = tf.Variable(tf.truncated_normal(shape=(84, 44), mean = self.mu, stddev = self.sigma))\n",
        "        self.output_bias = tf.Variable(tf.zeros(44))\n",
        "        self.logits =  tf.add((tf.matmul(self.fully_connected2, self.output_weights)), self.output_bias)\n",
        "        #self.logits = tf.one_hot(np.asarray(self.logits, np.int32), n_out)\n",
        "        #print(self.logits.get_shape())\n",
        "        \n",
        "        # Training operation\n",
        "        self.one_hot_y = tf.one_hot(y, n_out)\n",
        "        #print(self.one_hot_y.get_shape())\n",
        "        #print(self.logits.get_shape())\n",
        "        self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.one_hot_y)\n",
        "        self.loss_operation = tf.reduce_mean(self.cross_entropy)\n",
        "        #print(self.one_hot_y.get_shape())\n",
        "        #print(self.logits.get_shape())\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "        self.training_operation = self.optimizer.minimize(self.loss_operation)\n",
        "\n",
        "        # Accuracy operation\n",
        "        #print(self.one_hot_y.get_shape())\n",
        "        #print(self.logits.get_shape())\n",
        "        self.correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.one_hot_y,1))\n",
        "        #print(\"after correct pred\")\n",
        "        self.accuracy_operation = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
        "        #print(\"after acc op\")\n",
        "\n",
        "        # Saving all variables\n",
        "        self.saver = tf.train.Saver()\n",
        "    \n",
        "    def y_predict(self, X_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            print(\"in y_pred offset\")\n",
        "            batch_x = X_data[offset:offset+BATCH_SIZE]\n",
        "            y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(self.logits, 1), feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "            print(y_pred)\n",
        "        return y_pred\n",
        "    \n",
        "    def evaluate(self, X_data, y_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        total_accuracy = 0\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "            print(\"in eval offset\")\n",
        "            accuracy = sess.run(self.accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0, keep_prob_conv: 1.0 })\n",
        "            print(\"after acc in offset\")\n",
        "            total_accuracy += (accuracy * len(batch_x))\n",
        "        return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH6vbnVR28cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
        "y = tf.placeholder(tf.int32, (None))\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)       # For fully-connected layers\n",
        "keep_prob_conv = tf.placeholder(tf.float32)  # For convolutional layers\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "DIR = 'Saved_Models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQDHOKZ3Luu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1636
        },
        "outputId": "c962c7c3-c8d1-4b6f-e996-1db0f4cb290d"
      },
      "source": [
        "LeNet_Model = LeNet(n_out = num_classes)\n",
        "model_name = \"LeNet\"\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(Y_train)\n",
        "    print(\"Training ...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        #X_train, Y_train = shuffle(X_train, Y_train)\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            end = offset + BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[offset:end], Y_train[offset:end]\n",
        "            sess.run(LeNet_Model.training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob : 0.5, keep_prob_conv: 0.7})\n",
        "            \n",
        "        validation_accuracy = LeNet_Model.evaluate(X_test, Y_test)\n",
        "        print(\"EPOCH {} : Validation Accuracy = {:.3f}%\".format(i+1, (validation_accuracy*100)))\n",
        "    LeNet_Model.saver.save(sess, os.path.join(DIR, model_name))\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 53,
    }
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKI1Hg0Q9NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

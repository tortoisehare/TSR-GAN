{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mark2_TSFClassifier_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/Mark2_TSFClassifier_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isD9mtH373R4",
        "colab_type": "text"
      },
      "source": [
        "Author: Stephanie Tietz\n",
        "\n",
        "LeNet5 model design and grayscale preprocessing idea from: mohamedameen93 on full German Traffic Sign dataset\n",
        "\n",
        "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow\n",
        "\n",
        "Regularization options provided, Adadelta or Adam optimizer, trained on German TS Dataset plus \"not a sign\" images, optimized for 3 classes first then expanding to 44\n",
        "\n",
        "Multiclass Image Classification in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc_cvQN_70HP",
        "colab_type": "code",
        "outputId": "aa014e5f-09a0-49b7-fe01-c1088823b14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1187) #to help reproduce\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "#import random\n",
        "#import cv2\n",
        "#from skimage.filters import rank\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "#from keras.utils import np_utils\n",
        "#from keras import backend as K\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5l_XxOH8Lgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload data\n",
        "#from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#traindata = np.load('smalltrain.npy') #only 3 classes, both circle signs\n",
        "#traindata = np.load('alltrain.npy') #all classes\n",
        "\n",
        "#testdata = np.load('smalltest.npy')\n",
        "#testdata = np.load('alltest.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bDJvjGb8geR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindata = np.load('smalltrain2.npy') #smalltrain2 has triangle sign\n",
        "testdata = np.load('smalltest2.npy')\n",
        "\n",
        "print(traindata.shape) #expect (5620, 3073) for triangle dataset, (41109,3073) for all\n",
        "print(testdata.shape) #expect (1900, 3073) for triangle dataset, (13330,3073) for all\n",
        "print(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppQcdFyMxKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signs = []\n",
        "with open('signnames.csv', 'r') as csvfile:\n",
        "    signnames = csv.reader(csvfile, delimiter=',')\n",
        "    next(signnames,None)\n",
        "    for row in signnames:\n",
        "        signs.append(row[1])\n",
        "    csvfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMi6286r8tVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split into x and y\n",
        "X_train = traindata[:,:-1]\n",
        "Y_train = traindata[:,-1]\n",
        "Y_train = Y_train.reshape(len(Y_train),1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_test = testdata[:,:-1]\n",
        "Y_test = testdata[:,-1]\n",
        "Y_test = Y_test.reshape(len(Y_test),1)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "#reshape into (32,32,3) for each example for this model input\n",
        "X_train = (X_train.reshape(traindata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_train.shape)\n",
        "X_test = (X_test.reshape(testdata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLk-mamjn4LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#START OF DATA PREPROCESSING\n",
        "#Shuffle\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#Randomize (shuffle) the data\n",
        "print(Y_test)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "X_test, Y_test = shuffle(X_test, Y_test)\n",
        "print(Y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LWatNlVPog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make grayscale\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_P1x9lhSPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize data\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjrwooR2fwdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Expand dimensions to fit 4D input array\n",
        "\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_1efCDVRHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute mean image of training set and subtract from training images (not test images)\n",
        "chann_index_swap = np.swapaxes(X_train,0,3)\n",
        "mean_image = [[[sum(pixel)/len(pixel) for pixel in col] for col in row] for row in chann_index_swap]\n",
        "mean_image = np.swapaxes(mean_image,0,2)\n",
        "mean_image = np.swapaxes(mean_image,0,1)\n",
        "\n",
        "X_train = X_train - mean_image\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptTydNb8otG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 44 #change to 44 for alldata\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "\n",
        "#Useful image variables\n",
        "im_rows = 32\n",
        "im_cols = 32\n",
        "image_shape = (32, 32, 1)\n",
        "\n",
        "#might be useful later\n",
        "'''\n",
        "if K.image_dim_ordering() == 'th':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (3, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAxWJ3R-kR9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Histogram visualization of classes\n",
        "hist_data = np.histogram(Y_train, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_train, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,2500])\n",
        "plt.show()\n",
        "print(\"Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSB2mqBMMbiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the model\n",
        "Y_train = to_categorical(Y_train,num_classes)\n",
        "Y_test = to_categorical(Y_test,num_classes)\n",
        "\n",
        "pool_size = (2,2)\n",
        "kernel_size = (3,3)\n",
        "#num_filters = 32 #number of convolutional filters to use\n",
        "\n",
        "model = Sequential() #input 32x32x3 (or 32x32x1 if we use greyscale)\n",
        "#model.add(InputLayer(input_shape=[im_rows,im_cols,1]))\n",
        "\n",
        "#LAYER 1\n",
        "model.add(Convolution2D(filters=6, kernel_size=kernel_size, input_shape=image_shape)) #output 28x28x6\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2))) #output 14x14x6\n",
        "\n",
        "#LAYER 2\n",
        "model.add(Convolution2D(filters=16, kernel_size=kernel_size)) #output 10x10x16\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2))) #output 5x5x16\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten()) #to send to FC/Dense layers\n",
        "\n",
        "#LAYER 3, FC with 120 units\n",
        "model.add(Dense(120))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#LAYER 4, FC with 84 units\n",
        "model.add(Dense(84))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#LAYER 5 - output layer, need num_classes\n",
        "model.add(Dense(units=num_classes, activation='softmax')) #output num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKI1Hg0Q9NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "num_epochs = 32\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
        "#optimizer = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs = num_epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "print('Test score: ', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
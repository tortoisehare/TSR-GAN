{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mark2_TSFClassifier_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/Mark2_TSFClassifier_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isD9mtH373R4",
        "colab_type": "text"
      },
      "source": [
        "Author: Stephanie Tietz\n",
        "\n",
        "LeNet5 model design and grayscale preprocessing idea from: mohamedameen93 on full German Traffic Sign dataset\n",
        "\n",
        "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow\n",
        "\n",
        "Regularization options provided, Adadelta or Adam optimizer, trained on German TS Dataset plus \"not a sign\" images, optimized for 3 classes first then expanding to 44\n",
        "\n",
        "Multiclass Image Classification in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc_cvQN_70HP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1187) #to help reproduce\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "#import random\n",
        "#import cv2\n",
        "#from skimage.filters import rank\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "#from keras.utils import np_utils\n",
        "#from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5l_XxOH8Lgz",
        "colab_type": "code",
        "outputId": "0dbf77d4-20bf-42be-e4ae-528c6f7af1bd",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#upload data\n",
        "#from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#traindata = np.load('smalltrain.npy') #only 3 classes, both circle signs\n",
        "#traindata = np.load('alltrain.npy') #all classes\n",
        "\n",
        "#testdata = np.load('smalltest.npy')\n",
        "#testdata = np.load('alltest.npy')\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "training_file = 'train.p'\n",
        "testing_file = 'test.p'\n",
        "validation_file = 'valid.p'\n",
        "\n",
        "with open(training_file, mode='rb') as f:\n",
        "    tstrain = pickle.load(f)\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    tstest = pickle.load(f)\n",
        "with open(validation_file, mode='rb') as f:\n",
        "    tsvalid = pickle.load(f)\n",
        "    "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03fe24fb-e655-4b7d-8af1-d27ace78583f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-03fe24fb-e655-4b7d-8af1-d27ace78583f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.p to train.p\n",
            "Saving valid.p to valid.p\n",
            "Saving test.p to test.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TskHKwV0zO21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "num_train = X_train.shape[0]\n",
        "num_test = X_test.shape[0]\n",
        "num_valid = X_valid.shape[0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bDJvjGb8geR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#traindata = np.load('smalltrain2.npy') #smalltrain2 has triangle sign\n",
        "#testdata = np.load('smalltest2.npy')\n",
        "\n",
        "#traindata = np.load('tsrtrain.npy')\n",
        "#testdata = np.load('tsrtest.npy')\n",
        "\n",
        "#print(traindata.shape) #(39209,3073) for all\n",
        "#print(testdata.shape) #(12630,3073) for all\n",
        "#print(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppQcdFyMxKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signs = []\n",
        "#with open('signnames.csv', 'r') as csvfile:\n",
        "    #signnames = csv.reader(csvfile, delimiter=',')\n",
        "    #next(signnames,None)\n",
        "    #for row in signnames:\n",
        "     #   signs.append(row[1])\n",
        "    #csvfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMi6286r8tVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#split into x and y\n",
        "X_train = traindata[:,:-1]\n",
        "Y_train = traindata[:,-1]\n",
        "Y_train = Y_train.reshape(len(Y_train),1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_test = testdata[:,:-1]\n",
        "Y_test = testdata[:,-1]\n",
        "Y_test = Y_test.reshape(len(Y_test),1)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "#reshape into (32,32,3) for each example for this model input\n",
        "X_train = (X_train.reshape(traindata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_train.shape)\n",
        "X_test = (X_test.reshape(testdata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_test.shape)'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLk-mamjn4LL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a3b69f2-056c-415c-fff2-2db6c1ef125c"
      },
      "source": [
        "#START OF DATA PREPROCESSING\n",
        "#Shuffle\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#Randomize (shuffle) the data\n",
        "print(Y_train)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "#X_valid, Y_valid = shuffle(X_valid, Y_valid)\n",
        "#X_test, Y_test = shuffle(X_test, Y_test)\n",
        "print(Y_train)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[41 41 41 ... 25 25 25]\n",
            "[25  3  2 ... 13 18 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LWatNlVPog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5cc65d09-13f7-4f13-86dd-09884c4a99b5"
      },
      "source": [
        "#Make grayscale\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_valid.shape)\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "X_valid = np.dot(X_valid, grayscale)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_valid.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32, 3)\n",
            "(12630, 32, 32, 3)\n",
            "(4410, 32, 32, 3)\n",
            "(34799, 32, 32)\n",
            "(12630, 32, 32)\n",
            "(4410, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_P1x9lhSPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ec81f9e-04cc-44b2-9dc1-928f28ab36fe"
      },
      "source": [
        "#Normalize data\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "X_valid = np.array(X_valid)/255\n",
        "print(X_train.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjrwooR2fwdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5f5ac734-104f-41f6-8bd9-e0edec74f081"
      },
      "source": [
        "#Expand dimensions to fit 4D input array\n",
        "\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "print(X_test.shape)\n",
        "\n",
        "X_valid = np.expand_dims(X_valid,-1)\n",
        "print(X_valid.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32, 1)\n",
            "(12630, 32, 32, 1)\n",
            "(4410, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_1efCDVRHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute mean image of training set and subtract from training images (not test images)\n",
        "#chann_index_swap = np.swapaxes(X_train,0,3)\n",
        "#mean_image = [[[sum(pixel)/len(pixel) for pixel in col] for col in row] for row in chann_index_swap]\n",
        "#mean_image = np.swapaxes(mean_image,0,2)\n",
        "#mean_image = np.swapaxes(mean_image,0,1)\n",
        "\n",
        "#X_train = X_train - mean_image\n",
        "#print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptTydNb8otG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 43 #change to 44 for alldata\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "\n",
        "#Useful image variables\n",
        "im_rows = 32\n",
        "im_cols = 32\n",
        "image_shape = (32, 32, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAxWJ3R-kR9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "outputId": "cf48b461-86fa-406d-d16c-701fb996d535"
      },
      "source": [
        "#Histogram visualization of classes\n",
        "hist_data = np.histogram(Y_train, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_train, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,2500])\n",
        "plt.show()\n",
        "print(\"Train Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n",
        "\n",
        "hist_data = np.histogram(Y_valid, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_valid, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,250])\n",
        "plt.show()\n",
        "print(\"Valid Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n",
        "\n",
        "hist_data = np.histogram(Y_test, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_test, bins=range(num_classes+1), color = '#00ffCC')\n",
        "plt.axis([0,num_classes,0,1000])\n",
        "plt.show()\n",
        "print(\"Test Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0CSOmUASFKnDABJ6pQBIEmd+n+l0xmpIS03IwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Class with most examples:\n",
            "2 2010\n",
            "Class with least examples:\n",
            "37 180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZ0yACSpUwaAJHXKAJCkTv0/v0MHPtX43coAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Valid Class with most examples:\n",
            "13 240\n",
            "Class with least examples:\n",
            "42 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUqcMAEnqlAEgSZ36f4wfD8UA05bVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test Class with most examples:\n",
            "2 750\n",
            "Class with least examples:\n",
            "41 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSB2mqBMMbiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#Create the model\n",
        "Y_train = to_categorical(Y_train,num_classes)\n",
        "Y_test = to_categorical(Y_test,num_classes)\n",
        "Y_valid = to_categorical(Y_valid,num_classes)\n",
        "\n",
        "pool_size = (2,2)\n",
        "kernel_size = (3,3)\n",
        "#num_filters = 32 #number of convolutional filters to use\n",
        "\n",
        "model = Sequential() #input 32x32x3 (or 32x32x1 if we use greyscale)\n",
        "#model.add(InputLayer(input_shape=[im_rows,im_cols,1]))\n",
        "\n",
        "#LAYER 1\n",
        "model.add(Convolution2D(filters=6, kernel_size=kernel_size, input_shape=image_shape)) #output 28x28x6\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2))) #output 14x14x6\n",
        "\n",
        "#LAYER 2\n",
        "model.add(Convolution2D(filters=16, kernel_size=kernel_size)) #output 10x10x16\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2))) #output 5x5x16\n",
        "\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten()) #to send to FC/Dense layers\n",
        "\n",
        "#LAYER 3, FC with 120 units\n",
        "model.add(Dense(120))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#LAYER 4, FC with 84 units\n",
        "model.add(Dense(84))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#LAYER 5 - output layer, need num_classes\n",
        "model.add(Dense(units=num_classes, activation='softmax')) #output num_classes\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gQozorl2wrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet:  \n",
        "\n",
        "    def __init__(self, n_out=43, mu=0, sigma=0.1, learning_rate=0.001):\n",
        "        # Hyperparameters\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "\n",
        "        # Layer 1 (Convolutional): Input = 32x32x1. Output = 28x28x6.\n",
        "        self.filter1_width = 5\n",
        "        self.filter1_height = 5\n",
        "        self.input1_channels = 1\n",
        "        self.conv1_output = 6\n",
        "        # Weight and bias\n",
        "        self.conv1_weight = tf.Variable(tf.truncated_normal(\n",
        "            shape=(self.filter1_width, self.filter1_height, self.input1_channels, self.conv1_output),\n",
        "            mean = self.mu, stddev = self.sigma))\n",
        "        self.conv1_bias = tf.Variable(tf.zeros(self.conv1_output))\n",
        "        # Apply Convolution\n",
        "        self.conv1 = tf.nn.conv2d(x, self.conv1_weight, strides=[1, 1, 1, 1], padding='VALID') + self.conv1_bias\n",
        "        \n",
        "        # Activation:\n",
        "        self.conv1 = tf.nn.relu(self.conv1)\n",
        "        \n",
        "        # Pooling: Input = 28x28x6. Output = 14x14x6.\n",
        "        self.conv1 = tf.nn.max_pool(self.conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "        \n",
        "        # Layer 2 (Convolutional): Output = 10x10x16.\n",
        "        self.filter2_width = 5\n",
        "        self.filter2_height = 5\n",
        "        self.input2_channels = 6\n",
        "        self.conv2_output = 16\n",
        "        # Weight and bias\n",
        "        self.conv2_weight = tf.Variable(tf.truncated_normal(\n",
        "            shape=(self.filter2_width, self.filter2_height, self.input2_channels, self.conv2_output),\n",
        "            mean = self.mu, stddev = self.sigma))\n",
        "        self.conv2_bias = tf.Variable(tf.zeros(self.conv2_output))\n",
        "        # Apply Convolution\n",
        "        self.conv2 = tf.nn.conv2d(self.conv1, self.conv2_weight, strides=[1, 1, 1, 1], padding='VALID') + self.conv2_bias\n",
        "        \n",
        "        # Activation:\n",
        "        self.conv2 = tf.nn.relu(self.conv2)\n",
        "        \n",
        "        # Pooling: Input = 10x10x16. Output = 5x5x16.\n",
        "        self.conv2 = tf.nn.max_pool(self.conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "        \n",
        "        # Flattening: Input = 5x5x16. Output = 400.\n",
        "        self.fully_connected0 = Flatten()(self.conv2)\n",
        "        \n",
        "        # Layer 3 (Fully Connected): Input = 400. Output = 120.\n",
        "        self.connected1_weights = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = self.mu, stddev = self.sigma))\n",
        "        self.connected1_bias = tf.Variable(tf.zeros(120))\n",
        "        self.fully_connected1 = tf.add((tf.matmul(self.fully_connected0, self.connected1_weights)), self.connected1_bias)\n",
        "        \n",
        "        # Activation:\n",
        "        self.fully_connected1 = tf.nn.relu(self.fully_connected1)\n",
        "    \n",
        "        # Layer 4 (Fully Connected): Input = 120. Output = 84.\n",
        "        self.connected2_weights = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = self.mu, stddev = self.sigma))\n",
        "        self.connected2_bias = tf.Variable(tf.zeros(84))\n",
        "        self.fully_connected2 = tf.add((tf.matmul(self.fully_connected1, self.connected2_weights)), self.connected2_bias)\n",
        "        \n",
        "        # Activation.\n",
        "        self.fully_connected2 = tf.nn.relu(self.fully_connected2)\n",
        "    \n",
        "        # Layer 5 (Fully Connected): Input = 84. Output = 43.\n",
        "        self.output_weights = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = self.mu, stddev = self.sigma))\n",
        "        self.output_bias = tf.Variable(tf.zeros(43))\n",
        "        self.logits =  tf.add((tf.matmul(self.fully_connected2, self.output_weights)), self.output_bias)\n",
        "\n",
        "        # Training operation\n",
        "        self.one_hot_y = tf.one_hot(y, n_out)\n",
        "        self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.one_hot_y)\n",
        "        self.loss_operation = tf.reduce_mean(self.cross_entropy)\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "        self.training_operation = self.optimizer.minimize(self.loss_operation)\n",
        "\n",
        "        # Accuracy operation\n",
        "        self.correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.one_hot_y, 1))\n",
        "        self.accuracy_operation = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
        "\n",
        "        # Saving all variables\n",
        "        self.saver = tf.train.Saver()\n",
        "    \n",
        "    def y_predict(self, X_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x = X_data[offset:offset+BATCH_SIZE]\n",
        "            y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(self.logits, 1), \n",
        "                               feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "        return y_pred\n",
        "    \n",
        "    def evaluate(self, X_data, y_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        total_accuracy = 0\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "            accuracy = sess.run(self.accuracy_operation, \n",
        "                                feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0, keep_prob_conv: 1.0 })\n",
        "            total_accuracy += (accuracy * len(batch_x))\n",
        "        return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH6vbnVR28cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
        "y = tf.placeholder(tf.int32, (None))\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)       # For fully-connected layers\n",
        "keep_prob_conv = tf.placeholder(tf.float32)  # For convolutional layers\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "DIR = 'Saved_Models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQDHOKZ3Luu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e3b52c69-a2a0-47a5-ce35-090c4aeb8e6a"
      },
      "source": [
        "LeNet_Model = LeNet(n_out = num_classes)\n",
        "model_name = \"LeNet\"\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(Y_train)\n",
        "    print(\"Training ...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        #X_train, Y_train = shuffle(X_train, Y_train)\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            end = offset + BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[offset:end], Y_train[offset:end]\n",
        "            sess.run(LeNet_Model.training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob : 0.5, keep_prob_conv: 0.7})\n",
        "            \n",
        "        validation_accuracy = LeNet_Model.evaluate(X_valid, Y_valid)\n",
        "        print(\"EPOCH {} : Validation Accuracy = {:.3f}%\".format(i+1, (validation_accuracy*100)))\n",
        "    LeNet_Model.saver.save(sess, os.path.join(DIR, model_name))\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ...\n",
            "\n",
            "EPOCH 1 : Validation Accuracy = 73.741%\n",
            "EPOCH 2 : Validation Accuracy = 81.587%\n",
            "EPOCH 3 : Validation Accuracy = 86.009%\n",
            "EPOCH 4 : Validation Accuracy = 86.848%\n",
            "EPOCH 5 : Validation Accuracy = 88.231%\n",
            "EPOCH 6 : Validation Accuracy = 88.685%\n",
            "EPOCH 7 : Validation Accuracy = 88.367%\n",
            "EPOCH 8 : Validation Accuracy = 89.388%\n",
            "EPOCH 9 : Validation Accuracy = 87.415%\n",
            "EPOCH 10 : Validation Accuracy = 88.685%\n",
            "EPOCH 11 : Validation Accuracy = 87.755%\n",
            "EPOCH 12 : Validation Accuracy = 89.388%\n",
            "EPOCH 13 : Validation Accuracy = 89.002%\n",
            "EPOCH 14 : Validation Accuracy = 86.939%\n",
            "EPOCH 15 : Validation Accuracy = 88.209%\n",
            "EPOCH 16 : Validation Accuracy = 89.955%\n",
            "EPOCH 17 : Validation Accuracy = 89.592%\n",
            "EPOCH 18 : Validation Accuracy = 88.957%\n",
            "EPOCH 19 : Validation Accuracy = 89.796%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKI1Hg0Q9NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "batch_size = 64\n",
        "\n",
        "num_epochs = 32\n",
        "\n",
        "#optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
        "#optimizer = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs = num_epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "print('Test score: ', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mark3_TSFClassifier_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/TSRClassifier_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isD9mtH373R4",
        "colab_type": "text"
      },
      "source": [
        "Author: Stephanie Tietz\n",
        "\n",
        "LeNet5 model design and grayscale preprocessing idea from: mohamedameen93 on full German Traffic Sign dataset\n",
        "\n",
        "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow\n",
        "\n",
        "Regularization options provided, Adadelta or Adam optimizer, trained on German TS Dataset plus \"not a sign\" images, optimized for 3 classes first then expanding to 44\n",
        "\n",
        "Multiclass Image Classification in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc_cvQN_70HP",
        "colab_type": "code",
        "outputId": "5afbd3ad-2750-4035-e41c-5f87ca58e7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1187) #to help reproduce\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "#import random\n",
        "#import cv2\n",
        "from skimage.filters import rank\n",
        "import skimage.morphology as morp\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "#from keras.utils import np_utils\n",
        "#from keras import backend as K\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5l_XxOH8Lgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload data\n",
        "#from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#traindata = np.load('smalltrain.npy') #only 3 classes, both circle signs\n",
        "#traindata = np.load('alltrain.npy') #all classes\n",
        "\n",
        "#testdata = np.load('smalltest.npy')\n",
        "#testdata = np.load('alltest.npy')\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "training_file = 'train.p'\n",
        "testing_file = 'test.p'\n",
        "validation_file = 'valid.p'\n",
        "\n",
        "with open(training_file, mode='rb') as f:\n",
        "    tstrain = pickle.load(f)\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    tstest = pickle.load(f)\n",
        "with open(validation_file, mode='rb') as f:\n",
        "    tsvalid = pickle.load(f)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TskHKwV0zO21",
        "colab_type": "code",
        "outputId": "706591e7-cf54-48c6-c31c-f236f562e938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "num_train = X_train.shape[0]\n",
        "num_test = X_test.shape[0]\n",
        "num_valid = X_valid.shape[0]\n",
        "\n",
        "print(Y_train.shape)\n",
        "print(Y_valid.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799,)\n",
            "(4410,)\n",
            "(12630,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppQcdFyMxKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signs = []\n",
        "#with open('signnames.csv', 'r') as csvfile:\n",
        "    #signnames = csv.reader(csvfile, delimiter=',')\n",
        "    #next(signnames,None)\n",
        "    #for row in signnames:\n",
        "     #   signs.append(row[1])\n",
        "    #csvfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMi6286r8tVV",
        "colab_type": "code",
        "outputId": "5781460f-bcec-4f0a-9398-be8f2ff065fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "#split into x and y\n",
        "X_train = traindata[:,:-1]\n",
        "Y_train = traindata[:,-1]\n",
        "Y_train = Y_train.reshape(len(Y_train),1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_test = testdata[:,:-1]\n",
        "Y_test = testdata[:,-1]\n",
        "Y_test = Y_test.reshape(len(Y_test),1)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "#reshape into (32,32,3) for each example for this model input\n",
        "X_train = (X_train.reshape(traindata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_train.shape)\n",
        "X_test = (X_test.reshape(testdata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\n",
        "print(X_test.shape)\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#split into x and y\\nX_train = traindata[:,:-1]\\nY_train = traindata[:,-1]\\nY_train = Y_train.reshape(len(Y_train),1)\\nprint(X_train.shape)\\nprint(Y_train.shape)\\n\\nX_test = testdata[:,:-1]\\nY_test = testdata[:,-1]\\nY_test = Y_test.reshape(len(Y_test),1)\\nprint(X_test.shape)\\nprint(Y_test.shape)\\n\\n#reshape into (32,32,3) for each example for this model input\\nX_train = (X_train.reshape(traindata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\\nprint(X_train.shape)\\nX_test = (X_test.reshape(testdata.shape[0], 3, 32, 32)).transpose([0,2,3,1])\\nprint(X_test.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLk-mamjn4LL",
        "colab_type": "code",
        "outputId": "eb347635-2a80-4376-e2cd-e8b3b5d94b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#START OF DATA PREPROCESSING\n",
        "#Shuffle\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#Randomize (shuffle) the data\n",
        "print(Y_train)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "#X_valid, Y_valid = shuffle(X_valid, Y_valid)\n",
        "#X_test, Y_test = shuffle(X_test, Y_test)\n",
        "print(Y_train)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[41 41 41 ... 25 25 25]\n",
            "[25  3  2 ... 13 18 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LWatNlVPog",
        "colab_type": "code",
        "outputId": "4613d6f0-4157-4090-ac65-8ce1a9e25014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#Make grayscale\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_valid.shape)\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "X_valid = np.dot(X_valid, grayscale)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_valid.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32, 3)\n",
            "(12630, 32, 32, 3)\n",
            "(4410, 32, 32, 3)\n",
            "(34799, 32, 32)\n",
            "(12630, 32, 32)\n",
            "(4410, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_P1x9lhSPC",
        "colab_type": "code",
        "outputId": "4fca7309-7d20-49a5-d8dd-57c8981d2c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Normalize data\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "X_valid = np.array(X_valid)/255\n",
        "print(X_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjrwooR2fwdW",
        "colab_type": "code",
        "outputId": "56a5955c-3a2b-498c-e6b7-c7a0047fd7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Expand dimensions to fit 4D input array\n",
        "\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "print(X_test.shape)\n",
        "\n",
        "X_valid = np.expand_dims(X_valid,-1)\n",
        "print(X_valid.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32, 1)\n",
            "(12630, 32, 32, 1)\n",
            "(4410, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_1efCDVRHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute mean image of training set and subtract from training images (not test images)\n",
        "#chann_index_swap = np.swapaxes(X_train,0,3)\n",
        "#mean_image = [[[sum(pixel)/len(pixel) for pixel in col] for col in row] for row in chann_index_swap]\n",
        "#mean_image = np.swapaxes(mean_image,0,2)\n",
        "#mean_image = np.swapaxes(mean_image,0,1)\n",
        "\n",
        "#X_train = X_train - mean_image\n",
        "#print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptTydNb8otG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 43 #change to 44 for alldata\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "\n",
        "#Useful image variables\n",
        "im_rows = 32\n",
        "im_cols = 32\n",
        "image_shape = (32, 32, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAxWJ3R-kR9g",
        "colab_type": "code",
        "outputId": "7af875e2-1bd3-45fe-e397-a660cf684d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        }
      },
      "source": [
        "#Histogram visualization of classes\n",
        "hist_data = np.histogram(Y_train, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_train, bins=range(num_classes+1), color = '#00ffCC', histtype='bar', ec='black')\n",
        "plt.axis([0,num_classes,0,2500])\n",
        "plt.show()\n",
        "print(\"Train Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n",
        "\n",
        "hist_data = np.histogram(Y_valid, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_valid, bins=range(num_classes+1), color = '#00ffCC', histtype='bar', ec='black')\n",
        "plt.axis([0,num_classes,0,250])\n",
        "plt.show()\n",
        "print(\"Valid Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n",
        "\n",
        "hist_data = np.histogram(Y_test, bins=range(num_classes+1))\n",
        "hist_map = {}\n",
        "for occr,i in zip(hist_data[0], hist_data[1]):\n",
        "  hist_map[occr] = i\n",
        "\n",
        "plt.hist(Y_test, bins=range(num_classes+1), color = '#00ffCC', histtype='bar', ec='black')\n",
        "plt.axis([0,num_classes,0,1000])\n",
        "plt.show()\n",
        "print(\"Test Class with most examples:\")\n",
        "print(hist_map[np.amax(hist_data[0])],np.amax(hist_data[0]))\n",
        "print(\"Class with least examples:\")\n",
        "print(hist_map[np.amin(hist_data[0])],np.amin(hist_data[0]))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Class with most examples:\n",
            "2 2010\n",
            "Class with least examples:\n",
            "37 180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Valid Class with most examples:\n",
            "13 240\n",
            "Class with least examples:\n",
            "42 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test Class with most examples:\n",
            "2 750\n",
            "Class with least examples:\n",
            "41 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gQozorl2wrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet:  \n",
        "\n",
        "    def __init__(self, n_out=43, mu=0, sigma=0.1, learning_rate=0.001):\n",
        "        # Hyperparameters\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "\n",
        "        # Layer 1 (Convolutional): Input = 32x32x1. Output = 28x28x6.\n",
        "        self.filter1_width = 5\n",
        "        self.filter1_height = 5\n",
        "        self.input1_channels = 1\n",
        "        self.conv1_output = 6\n",
        "        # Weight and bias\n",
        "        self.conv1_weight = tf.Variable(tf.truncated_normal(\n",
        "            shape=(self.filter1_width, self.filter1_height, self.input1_channels, self.conv1_output),\n",
        "            mean = self.mu, stddev = self.sigma))\n",
        "        self.conv1_bias = tf.Variable(tf.zeros(self.conv1_output))\n",
        "        # Apply Convolution\n",
        "        self.conv1 = tf.nn.conv2d(x, self.conv1_weight, strides=[1, 1, 1, 1], padding='VALID') + self.conv1_bias\n",
        "        \n",
        "        # Activation:\n",
        "        self.conv1 = tf.nn.relu(self.conv1)\n",
        "        \n",
        "        # Pooling: Input = 28x28x6. Output = 14x14x6.\n",
        "        self.conv1 = tf.nn.max_pool(self.conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "        \n",
        "        # Layer 2 (Convolutional): Output = 10x10x16.\n",
        "        self.filter2_width = 5\n",
        "        self.filter2_height = 5\n",
        "        self.input2_channels = 6\n",
        "        self.conv2_output = 16\n",
        "        # Weight and bias\n",
        "        self.conv2_weight = tf.Variable(tf.truncated_normal(\n",
        "            shape=(self.filter2_width, self.filter2_height, self.input2_channels, self.conv2_output),\n",
        "            mean = self.mu, stddev = self.sigma))\n",
        "        self.conv2_bias = tf.Variable(tf.zeros(self.conv2_output))\n",
        "        # Apply Convolution\n",
        "        self.conv2 = tf.nn.conv2d(self.conv1, self.conv2_weight, strides=[1, 1, 1, 1], padding='VALID') + self.conv2_bias\n",
        "        \n",
        "        # Activation:\n",
        "        self.conv2 = tf.nn.relu(self.conv2)\n",
        "        \n",
        "        # Pooling: Input = 10x10x16. Output = 5x5x16.\n",
        "        self.conv2 = tf.nn.max_pool(self.conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "        \n",
        "        # Flattening: Input = 5x5x16. Output = 400.\n",
        "        self.fully_connected0 = Flatten()(self.conv2)\n",
        "        \n",
        "        # Layer 3 (Fully Connected): Input = 400. Output = 120.\n",
        "        self.connected1_weights = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = self.mu, stddev = self.sigma))\n",
        "        self.connected1_bias = tf.Variable(tf.zeros(120))\n",
        "        self.fully_connected1 = tf.add((tf.matmul(self.fully_connected0, self.connected1_weights)), self.connected1_bias)\n",
        "        \n",
        "        # Activation:\n",
        "        self.fully_connected1 = tf.nn.relu(self.fully_connected1)\n",
        "    \n",
        "        # Layer 4 (Fully Connected): Input = 120. Output = 84.\n",
        "        self.connected2_weights = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = self.mu, stddev = self.sigma))\n",
        "        self.connected2_bias = tf.Variable(tf.zeros(84))\n",
        "        self.fully_connected2 = tf.add((tf.matmul(self.fully_connected1, self.connected2_weights)), self.connected2_bias)\n",
        "        \n",
        "        # Activation.\n",
        "        self.fully_connected2 = tf.nn.relu(self.fully_connected2)\n",
        "    \n",
        "        # Layer 5 (Fully Connected): Input = 84. Output = 43.\n",
        "        self.output_weights = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = self.mu, stddev = self.sigma))\n",
        "        self.output_bias = tf.Variable(tf.zeros(43))\n",
        "        self.logits =  tf.add((tf.matmul(self.fully_connected2, self.output_weights)), self.output_bias)\n",
        "\n",
        "        # Training operation\n",
        "        self.one_hot_y = tf.one_hot(y, n_out)\n",
        "        self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.one_hot_y)\n",
        "        self.loss_operation = tf.reduce_mean(self.cross_entropy)\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "        self.training_operation = self.optimizer.minimize(self.loss_operation)\n",
        "\n",
        "        # Accuracy operation\n",
        "        self.correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.one_hot_y, 1))\n",
        "        self.accuracy_operation = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
        "\n",
        "        # Saving all variables\n",
        "        self.saver = tf.train.Saver()\n",
        "    \n",
        "    def y_predict(self, X_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x = X_data[offset:offset+BATCH_SIZE]\n",
        "            y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(self.logits, 1), \n",
        "                               feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "        return y_pred\n",
        "    \n",
        "    def evaluate(self, X_data, y_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        total_accuracy = 0\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "            accuracy = sess.run(self.accuracy_operation, \n",
        "                                feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0, keep_prob_conv: 1.0 })\n",
        "            total_accuracy += (accuracy * len(batch_x))\n",
        "        return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH6vbnVR28cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
        "y = tf.placeholder(tf.int32, (None))\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)       # For fully-connected layers\n",
        "keep_prob_conv = tf.placeholder(tf.float32)  # For convolutional layers\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 20\n",
        "DIR = 'Saved_Models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQDHOKZ3Luu",
        "colab_type": "code",
        "outputId": "9f4fae1b-ddb4-4dd6-c3c4-4c1bf2943a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "LeNet_Model = LeNet(n_out = num_classes)\n",
        "model_name = \"LeNet\"\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(Y_train)\n",
        "    print(\"Training ...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        #X_train, Y_train = shuffle(X_train, Y_train)\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            end = offset + BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[offset:end], Y_train[offset:end]\n",
        "            sess.run(LeNet_Model.training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob : 0.6, keep_prob_conv: 0.8})\n",
        "            \n",
        "        validation_accuracy = LeNet_Model.evaluate(X_valid, Y_valid)\n",
        "        print(\"EPOCH {} : Validation Accuracy = {:.3f}%\".format(i+1, (validation_accuracy*100)))\n",
        "    LeNet_Model.saver.save(sess, os.path.join(DIR, model_name))\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Training ...\n",
            "\n",
            "EPOCH 1 : Validation Accuracy = 81.429%\n",
            "EPOCH 2 : Validation Accuracy = 85.624%\n",
            "EPOCH 3 : Validation Accuracy = 86.961%\n",
            "EPOCH 4 : Validation Accuracy = 89.297%\n",
            "EPOCH 5 : Validation Accuracy = 89.819%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKI1Hg0Q9NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    LeNet_Model.saver.restore(sess, os.path.join(DIR, \"LeNet\"))\n",
        "    y_pred = LeNet_Model.y_predict(X_test)\n",
        "    test_accuracy = sum(Y_test == y_pred)/len(Y_test)\n",
        "    print(\"Test Accuracy = {:.1f}%\".format(test_accuracy*100))\n",
        "    \n",
        "\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = np.log(.0001 + cm)\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Log of normalized Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
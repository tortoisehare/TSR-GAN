{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fullGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/fullGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABnslutLuWVE",
        "colab_type": "code",
        "outputId": "38c5c7f7-d8ee-4a9d-a106-c45ea710fd9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!mkdir weights\n",
        "!mkdir weights/target_model\n",
        "!mkdir weights/generator\n",
        "!mkdir weights/discriminator\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘weights’: File exists\n",
            "mkdir: cannot create directory ‘weights/target_model’: File exists\n",
            "mkdir: cannot create directory ‘weights/generator’: File exists\n",
            "mkdir: cannot create directory ‘weights/discriminator’: File exists\n",
            "sample_data  test.p  train.p  valid.p  weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-dNiamCtfBr",
        "colab_type": "code",
        "outputId": "4b8c1455-d643-4356-a984-5dd005b7f156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "#TARGET CLASSIFIER\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1187) #to help reproduce\n",
        "\n",
        "#from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "#import random\n",
        "#import cv2\n",
        "#from skimage.filters import rank\n",
        "#import skimage.morphology as morp\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#from keras.utils import to_categorical\n",
        "#from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "#from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "\n",
        "class Target:\n",
        "    def __init__(self, lr=0.001, epochs=5, n_input=32, n_classes=43, batch_size=20, restore=0):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.n_input = 32\n",
        "        self.n_classes = 43\n",
        "        self.batch_size = batch_size\n",
        "        self.restore = restore\n",
        "\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    \n",
        "    '''\n",
        "    def next_batch(self, X, Y, i, batch_size):\n",
        "      idx = i*batch_size\n",
        "      idx_n = idx + batch_size\n",
        "      return X[idx:idx_n], Y[idx:idx_n]\n",
        "      '''\n",
        "    \n",
        "    def Model(self, x):\n",
        "        with tf.variable_scope('Model', reuse=tf.AUTO_REUSE):\n",
        "            # Hyperparameters\n",
        "            mu = 0\n",
        "            sigma = 0.1\n",
        "            n_out = self.n_classes\n",
        "            learning_rate = self.lr\n",
        "\n",
        "            # Layer 1 (Convolutional): Input = 32x32x1. Output = 28x28x6.\n",
        "            filter1_width = 5\n",
        "            filter1_height = 5\n",
        "            input1_channels = 1\n",
        "            conv1_output = 6\n",
        "            # Weight and bias\n",
        "            conv1_weight = tf.Variable(tf.truncated_normal(\n",
        "                shape=(filter1_width, filter1_height, input1_channels, conv1_output),\n",
        "                mean = mu, stddev = sigma))\n",
        "            conv1_bias = tf.Variable(tf.zeros(conv1_output))\n",
        "\n",
        "            # Apply Convolution\n",
        "            conv1 = tf.nn.conv2d(x, conv1_weight, strides=[1, 1, 1, 1], padding='VALID') + conv1_bias\n",
        "\n",
        "            # Activation:\n",
        "            conv1 = tf.nn.relu(conv1)\n",
        "\n",
        "            # Pooling: Input = 28x28x6. Output = 14x14x6.\n",
        "            conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "\n",
        "            # Layer 2 (Convolutional): Output = 10x10x16.\n",
        "            filter2_width = 5\n",
        "            filter2_height = 5\n",
        "            input2_channels = 6\n",
        "            conv2_output = 16\n",
        "            # Weight and bias\n",
        "            conv2_weight = tf.Variable(tf.truncated_normal(\n",
        "                shape=(filter2_width, filter2_height, input2_channels, conv2_output),\n",
        "                mean = mu, stddev = sigma))\n",
        "            conv2_bias = tf.Variable(tf.zeros(conv2_output))\n",
        "\n",
        "            # Apply Convolution\n",
        "            conv2 = tf.nn.conv2d(conv1, conv2_weight, strides=[1, 1, 1, 1], padding='VALID') + conv2_bias\n",
        "\n",
        "            # Activation:\n",
        "            conv2 = tf.nn.relu(conv2)\n",
        "\n",
        "            # Pooling: Input = 10x10x16. Output = 5x5x16.\n",
        "            conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "\n",
        "            # Flattening: Input = 5x5x16. Output = 400.\n",
        "            fully_connected0 = Flatten()(conv2)\n",
        "\n",
        "            # Layer 3 (Fully Connected): Input = 400. Output = 120.\n",
        "            connected1_weights = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
        "            connected1_bias = tf.Variable(tf.zeros(120))\n",
        "            fully_connected1 = tf.add((tf.matmul(fully_connected0, connected1_weights)), connected1_bias)\n",
        "\n",
        "            # Activation:\n",
        "            fully_connected1 = tf.nn.relu(fully_connected1)\n",
        "\n",
        "            # Layer 4 (Fully Connected): Input = 120. Output = 84.\n",
        "            connected2_weights = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
        "            connected2_bias = tf.Variable(tf.zeros(84))\n",
        "            fully_connected2 = tf.add((tf.matmul(fully_connected1, connected2_weights)), connected2_bias)\n",
        "\n",
        "            # Activation.\n",
        "            fully_connected2 = tf.nn.relu(fully_connected2)\n",
        "    \n",
        "            # Layer 5 (Fully Connected): Input = 84. Output = 43.\n",
        "            output_weights = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
        "            output_bias = tf.Variable(tf.zeros(43))\n",
        "            logits =  tf.add((tf.matmul(fully_connected2, output_weights)), output_bias)\n",
        "\n",
        "            probs = tf.nn.sigmoid(logits)\n",
        "            \n",
        "            return logits, probs\n",
        "    \n",
        "    \n",
        "    \n",
        "    def test(self, X_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x = X_data[offset:offset+BATCH_SIZE]\n",
        "            y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(logits, 1), \n",
        "                               feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "        return y_pred\n",
        "    \n",
        "    \n",
        "    def train(self, X_train, Y_train, X_valid, Y_valid):\n",
        "        #placeholders for inputs\n",
        "        x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
        "        y = tf.placeholder(tf.int32, (None))\n",
        "\n",
        "        keep_prob = tf.placeholder(tf.float32)       # For fully-connected layers\n",
        "        keep_prob_conv = tf.placeholder(tf.float32)\n",
        "\n",
        "        #define graph\n",
        "        logits, _ = self.Model(x)\n",
        "        \n",
        "              # Training operation\n",
        "        one_hot_y = tf.one_hot(y, 43)\n",
        "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=one_hot_y)\n",
        "        loss_operation = tf.reduce_mean(cross_entropy)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate = self.lr)\n",
        "        training_operation = optimizer.minimize(loss_operation)\n",
        "\n",
        "        # Accuracy operation\n",
        "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
        "        accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "          # Saving all variables\n",
        "        saver = tf.train.Saver()\n",
        "\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            num_train = len(Y_train)\n",
        "            num_valid = len(Y_valid)\n",
        "            print(\"Training ...\")\n",
        "            print()\n",
        "            EPOCHS = self.epochs\n",
        "            BATCH_SIZE = self.batch_size\n",
        "            DIR = \"./weights/target_model\"\n",
        "            total_batch = int(X_train.shape[0] / self.batch_size)\n",
        "\n",
        "            for i in range(EPOCHS):\n",
        "                avg_cost = 0.\n",
        "                total_accuracy = 0\n",
        "                validation_accuracy = 0\n",
        "                #Train set\n",
        "                for offset in range(0, num_train, BATCH_SIZE):\n",
        "                    end = offset + BATCH_SIZE\n",
        "                    batch_x, batch_y = X_train[offset:end], Y_train[offset:end]\n",
        "                    _, c = sess.run([training_operation, loss_operation], feed_dict={x: batch_x, y: batch_y, keep_prob : 0.6, keep_prob_conv: 0.8})\n",
        "                    avg_cost += c / total_batch\n",
        "                    \n",
        "                    #Validation Set\n",
        "                for offset in range(0, num_valid, BATCH_SIZE):\n",
        "                    end = offset + BATCH_SIZE\n",
        "                    batch_x, batch_y = X_valid[offset:end], Y_valid[offset:end]\n",
        "                    accuracy = sess.run(accuracy_operation, \n",
        "                                    feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0, keep_prob_conv: 1.0 })\n",
        "                    total_accuracy += (accuracy * len(batch_x))\n",
        "                    validation_accuracy = total_accuracy / num_valid\n",
        "                    #print(\"Validation Accuracy = {:.3f}%\".format(validation_accuracy*100))\n",
        "                    \n",
        "                print(\"Epoch: \", '%04d' % (i+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
        "                print(\"EPOCH {} : Validation Accuracy = {:.3f}%\".format(i+1, (validation_accuracy*100)))\n",
        "            \n",
        "            \n",
        "            #Test set\n",
        "            num_examples = len(X_test)\n",
        "            y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "            #sess = tf.get_default_session()\n",
        "            for offset in range(0, num_examples, BATCH_SIZE):\n",
        "                batch_x = X_test[offset:offset+BATCH_SIZE]\n",
        "                y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(logits, 1), \n",
        "                                   feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "            test_accuracy = sum(Y_test == y_pred)/len(Y_test)\n",
        "            print(\"Test Accuracy = {:.1f}%\".format(test_accuracy*100))\n",
        "\n",
        "            cm = confusion_matrix(Y_test, y_pred)\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cm = np.log(.0001 + cm)\n",
        "            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "            plt.title('Log of normalized Confusion Matrix')\n",
        "            plt.ylabel('True label')\n",
        "            plt.xlabel('Predicted label')\n",
        "            plt.show()\n",
        "            \n",
        "            saver.save(sess, \"./weights/target_model/model\")\n",
        "            print(\"Model saved\")\n",
        "            sess.close()\n",
        "\n",
        "   \n",
        "      \n",
        "      \n",
        "import pickle\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    training_file = 'train.p'\n",
        "    testing_file = 'test.p'\n",
        "    validation_file = 'valid.p'\n",
        "\n",
        "    with open(training_file, mode='rb') as f:\n",
        "        tstrain = pickle.load(f)\n",
        "    with open(testing_file, mode='rb') as f:\n",
        "        tstest = pickle.load(f)\n",
        "    with open(validation_file, mode='rb') as f:\n",
        "        tsvalid = pickle.load(f)\n",
        "\n",
        "    X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "    X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "    X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "    #shuffle training set\n",
        "    X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "    #grayscale images\n",
        "    grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "    X_test = np.dot(X_test, grayscale)\n",
        "    X_train = np.dot(X_train, grayscale)\n",
        "    X_valid = np.dot(X_valid, grayscale)\n",
        "\n",
        "\n",
        "    #normalize\n",
        "    X_train = np.array(X_train)/255\n",
        "    X_test = np.array(X_test)/255\n",
        "    X_valid = np.array(X_valid)/255\n",
        "\n",
        "    #expand dimensions to fit 4D input array\n",
        "    X_train = np.expand_dims(X_train,-1)\n",
        "    X_test = np.expand_dims(X_test,-1)\n",
        "    X_valid = np.expand_dims(X_valid,-1)\n",
        "\n",
        "    assert(len(X_train)==len(Y_train))\n",
        "    n_train = len(X_train)\n",
        "    assert(len(X_test)==len(Y_test))\n",
        "    n_test = len(X_test)\n",
        "\n",
        "    cnn = Target()\n",
        "    cnn.train(X_train, Y_train, X_valid, Y_valid)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Training ...\n",
            "\n",
            "Epoch:  0001 cost= 1.202183108\n",
            "EPOCH 1 : Validation Accuracy = 83.016%\n",
            "Epoch:  0002 cost= 0.278367689\n",
            "EPOCH 2 : Validation Accuracy = 89.002%\n",
            "Epoch:  0003 cost= 0.153129038\n",
            "EPOCH 3 : Validation Accuracy = 89.955%\n",
            "Epoch:  0004 cost= 0.106524747\n",
            "EPOCH 4 : Validation Accuracy = 90.023%\n",
            "Epoch:  0005 cost= 0.074324498\n",
            "EPOCH 5 : Validation Accuracy = 89.637%\n",
            "Test Accuracy = 88.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAEWCAYAAAB8A8JQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2laXHD7-tmk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generator\n",
        "'''\n",
        "\tGenerator definition for AdvGAN\n",
        "\tref: https://arxiv.org/pdf/1801.02610.pdf\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# helper function for convolution -> instance norm -> relu\n",
        "def ConvInstNormRelu(x, filters, kernel_size=3, strides=1):\n",
        "\tConv = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tInstNorm = tf.contrib.layers.instance_norm(Conv)\n",
        "\n",
        "\treturn tf.nn.relu(InstNorm)\n",
        "\n",
        "\n",
        "# helper function for trans convolution -> instance norm -> relu\n",
        "def TransConvInstNormRelu(x, filters, kernel_size=3, strides=2):\n",
        "\tTransConv = tf.layers.conv2d_transpose(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tInstNorm = tf.contrib.layers.instance_norm(TransConv)\n",
        "\n",
        "\treturn tf.nn.relu(InstNorm)\n",
        "\n",
        "# helper function for residual block of 2 convolutions with same num filters\n",
        "# in the same style as ConvInstNormRelu\n",
        "def ResBlock(x, training, filters=32, kernel_size=3, strides=1):\n",
        "\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tconv1_norm = tf.layers.batch_normalization(conv1, training=training)\n",
        "\n",
        "\tconv1_relu = tf.nn.relu(conv1_norm)\n",
        "\n",
        "\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=conv1_relu,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tconv2_norm = tf.layers.batch_normalization(conv2, training=training)\n",
        "\n",
        "\n",
        "\treturn x + conv2_norm\n",
        "\n",
        "\n",
        "def generator(x, training):\n",
        "\twith tf.variable_scope('g_weights', reuse=tf.AUTO_REUSE): #True\n",
        "\t\t# input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\t# define first three conv + inst + relu layers\n",
        "\t\tc1 = ConvInstNormRelu(x, filters=8, kernel_size=3, strides=1)\n",
        "\t\td1 = ConvInstNormRelu(c1, filters=16, kernel_size=3, strides=2)\n",
        "\t\td2 = ConvInstNormRelu(d1, filters=32, kernel_size=3, strides=2)\n",
        "\n",
        "\t\t# define residual blocks\n",
        "\t\trb1 = ResBlock(d2, training, filters=32)\n",
        "\t\trb2 = ResBlock(rb1, training, filters=32)\n",
        "\t\trb3 = ResBlock(rb2, training, filters=32)\n",
        "\t\trb4 = ResBlock(rb3, training, filters=32)\n",
        "\n",
        "\t\t# upsample using conv transpose\n",
        "\t\tu1 = TransConvInstNormRelu(rb4, filters=16, kernel_size=3, strides=2)\n",
        "\t\tu2 = TransConvInstNormRelu(u1, filters=8, kernel_size=3, strides=2)\n",
        "\n",
        "\t\t# final layer block\n",
        "\t\tout = tf.layers.conv2d_transpose(\n",
        "\t\t\t\t\t\tinputs=u2,\n",
        "\t\t\t\t\t\tfilters=x.get_shape()[-1].value, # or 3 if RGB image\n",
        "\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\tstrides=1,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\t# out = tf.contrib.layers.instance_norm(out)\n",
        "\n",
        "\t\treturn tf.nn.tanh(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKYLa86WtyLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Discriminator\n",
        "'''\n",
        "\tDiscriminator definition for AdvGAN\n",
        "\tref: https://arxiv.org/pdf/1801.02610.pdf\n",
        "'''\n",
        "\n",
        "#import tensorflow as tf\n",
        "\n",
        "def discriminator(x, training):\n",
        "\twith tf.variable_scope('d_weights', reuse=tf.AUTO_REUSE):\n",
        "\t\t# input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\t\tfilters=8,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\t\tconv1 = tf.nn.leaky_relu(conv1, alpha=0.2)\n",
        "\n",
        "\t\t\n",
        "\t\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=conv1,\n",
        "\t\t\t\t\t\t\tfilters=16,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\tin1 = tf.contrib.layers.instance_norm(conv2)\n",
        "\t\tconv2 = tf.nn.leaky_relu(in1, alpha=0.2)\n",
        "\n",
        "\t\tconv3 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=conv2,\n",
        "\t\t\t\t\t\t\tfilters=32,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\t#in2 = tf.contrib.layers.instance_norm(conv3)\n",
        "\t\tin2 = tf.contrib.layers.instance_norm(conv3)\n",
        "\t\tconv3 = tf.nn.leaky_relu(in2, alpha=0.2)\n",
        "\t\tflat = tf.layers.flatten(conv3)\n",
        "\t\tlogits = tf.layers.dense(flat, 1)\n",
        "\n",
        "\t\tprobs = tf.nn.sigmoid(logits)\n",
        "\n",
        "\t\treturn logits, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "288LCGWawCVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1415
        },
        "outputId": "cb06b606-24af-49af-9f02-0f9e6092e31e"
      },
      "source": [
        "import tensorflow as tf\n",
        "#from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os, sys\n",
        "import random\n",
        "\n",
        "#make sure GAN_setup.py is in connected folder\n",
        "#from GAN_setup import generator, discriminator\n",
        "\n",
        "#ctargon created class Target and defined/trained his target model in there, then called here\n",
        "#import Target as target_model\n",
        "\n",
        "\n",
        "# get the next batch based on x, y, and the iteration (based on batch_size)\n",
        "def next_batch(X, Y, i, batch_size):\n",
        "    idx = i * batch_size\n",
        "    idx_n = i * batch_size + batch_size\n",
        "    return X[idx:idx_n], Y[idx:idx_n]\n",
        "\n",
        "# loss function to encourage misclassification after perturbation\n",
        "def adv_loss(preds, labels, is_targeted):\n",
        "    real = tf.reduce_sum(labels * preds, 1)\n",
        "    other = tf.reduce_max((1 - labels) * preds - (labels * 10000), 1)\n",
        "    if is_targeted:\n",
        "        return tf.reduce_sum(tf.maximum(0.0, other - real))\n",
        "    return tf.reduce_sum(tf.maximum(0.0, real - other))\n",
        "\n",
        "# loss function to influence the perturbation to be as close to 0 as possible\n",
        "def perturb_loss(preds, thresh=0.3):\n",
        "    zeros = tf.zeros((tf.shape(preds)[0]))\n",
        "    return tf.reduce_mean(tf.maximum(zeros, tf.norm(tf.reshape(preds, (tf.shape(preds)[0], -1)), axis=1) - thresh))\n",
        "\n",
        "\n",
        "# function that defines ops, graphs, and training procedure for AdvGAN framework\n",
        "def AdvGAN(X, y, X_test, y_test, epochs=50, batch_size=128, target=3):\n",
        "    #print(X_train.shape)\n",
        "    #print(y.shape[-1]) is num_images\n",
        "    print(\"y shape\")\n",
        "    print(y.shape)\n",
        "    print(\"y_test shape\")\n",
        "    print(y_test.shape)\n",
        "    \n",
        "    # placeholder definitions\n",
        "    x_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "    t = tf.placeholder(tf.float32, [None, 43]) # target placeholder\n",
        "    print(\"t shape)\")\n",
        "    print(t.shape)\n",
        "    is_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "    #-----------------------------------------------------------------------------------\n",
        "    # MODEL DEFINITIONS\n",
        "    is_targeted = False\n",
        "    if target in range(0, 43):\n",
        "        is_targeted = True\n",
        "\n",
        "    # gather target model\n",
        "    f = Target()\n",
        "\n",
        "    thresh = 0.3\n",
        "\n",
        "    # generate perturbation, add to original input image(s)\n",
        "    perturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "    x_perturbed = perturb + x_pl\n",
        "    x_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "    print(x_perturbed.shape)\n",
        "\n",
        "    # pass real and perturbed image to discriminator and the target model\n",
        "    d_real_logits, d_real_probs = discriminator(x_pl, is_training)\n",
        "    d_fake_logits, d_fake_probs = discriminator(x_perturbed, is_training)\n",
        "    print(d_fake_probs.shape)#1\n",
        "    # pass real and perturbed images to the model we are trying to fool\n",
        "    f_real_logits, f_real_probs = f.Model(x_pl)\n",
        "    f_fake_logits, f_fake_probs = f.Model(x_perturbed)\n",
        "    print(f_fake_probs.shape) #43\n",
        "\n",
        "    # generate labels for discriminator (optionally smooth labels for stability)\n",
        "    smooth = 0.0\n",
        "    d_labels_real = tf.ones_like(d_real_probs) * (1 - smooth)\n",
        "    d_labels_fake = tf.zeros_like(d_fake_probs)\n",
        "\n",
        "    #-----------------------------------------------------------------------------------\n",
        "    # LOSS DEFINITIONS\n",
        "    # discriminator loss\n",
        "    d_loss_real = tf.losses.mean_squared_error(predictions=d_real_probs, labels=d_labels_real)\n",
        "    d_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=d_labels_fake)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    # generator loss\n",
        "    g_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=tf.ones_like(d_fake_probs))\n",
        "\n",
        "    # perturbation loss (minimize overall perturbation)\n",
        "    l_perturb = perturb_loss(perturb, thresh)\n",
        "\n",
        "    # adversarial loss (encourage misclassification)\n",
        "    l_adv = adv_loss(f_fake_probs, t, is_targeted)\n",
        "\n",
        "    # weights for generator loss function\n",
        "    alpha = 1.0\n",
        "    beta = 5.0\n",
        "    g_loss = l_adv + alpha*g_loss_fake + beta*l_perturb \n",
        "\n",
        "    # ----------------------------------------------------------------------------------\n",
        "    # gather variables for training/restoring\n",
        "    t_vars = tf.trainable_variables()\n",
        "    f_vars = [var for var in t_vars if 'Model' in var.name]\n",
        "    d_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "    g_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "    # define optimizers for discriminator and generator\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        d_opt = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n",
        "        g_opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "\t# create saver objects for the target model, generator, and discriminator\n",
        "    saver = tf.train.Saver(f_vars)\n",
        "    g_saver = tf.train.Saver(g_vars)\n",
        "    d_saver = tf.train.Saver(d_vars)\n",
        "\n",
        "    init  = tf.global_variables_initializer()\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    sess.run(init)\n",
        "    \n",
        "    # load the pretrained target model\n",
        "    #try:\n",
        "       # saver.restore(sess, \"./weights/target_model/model\")\n",
        "    #except:\n",
        "       # print(\"make sure to train the target model first...\")\n",
        "       # sys.exit(1)\n",
        "\n",
        "    \n",
        "    new_saver = tf.train.import_meta_graph('./weights/target_model/model.meta')\n",
        "    new_saver.restore(sess, tf.train.latest_checkpoint('./weights/target_model'))\n",
        "    #path_to_ckpt_data = './weights/target_model/model.data-00000-of-00001'\n",
        "    #new_saver.restore(sess, path_to_ckpt_data)\n",
        "    \n",
        "    print(\"Pretrained model loaded\")\n",
        "    \n",
        "    total_batches = int(X.shape[0] / batch_size)\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        loss_D_sum = 0.0\n",
        "        loss_G_fake_sum = 0.0\n",
        "        loss_perturb_sum = 0.0\n",
        "        loss_adv_sum = 0.0\n",
        "\n",
        "        for i in range(total_batches):\n",
        "\n",
        "            batch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "            # if targeted, create one hot vectors of the target\n",
        "            if is_targeted:\n",
        "                targets = np.full((batch_y.shape[0],), target)\n",
        "                batch_y = np.eye(43)[targets]\n",
        "\n",
        "            # train the discriminator first n times\n",
        "            for _ in range(1):\n",
        "                _, loss_D_batch = sess.run([d_opt, d_loss], feed_dict={x_pl: batch_x, \\\n",
        "                                           is_training: True})\n",
        "\n",
        "            print(batch_x.shape)\n",
        "            print(batch_y.shape)\n",
        "            \n",
        "\t\t\t       # train the generator n times\n",
        "            for _ in range(1):\n",
        "                \n",
        "                _, loss_G_fake_batch, loss_adv_batch, loss_perturb_batch = \\\n",
        "                        sess.run([g_opt, g_loss_fake, l_adv, l_perturb], \\\n",
        "                              feed_dict={x_pl: batch_x, \\\n",
        "                                     t: batch_y, \\\n",
        "                                     is_training: True})\n",
        "            loss_D_sum += loss_D_batch\n",
        "            loss_G_fake_sum += loss_G_fake_batch\n",
        "            loss_perturb_sum += loss_perturb_batch\n",
        "            loss_adv_sum += loss_adv_batch\n",
        "\n",
        "        print(\"epoch %d:\\nloss_D: %.3f, loss_G_fake: %.3f, \\\n",
        "            \\nloss_perturb: %.3f, loss_adv: %.3f, \\n\" %\n",
        "            (epoch + 1, loss_D_sum/total_batches, loss_G_fake_sum/total_batches,\n",
        "            loss_perturb_sum/total_batches, loss_adv_sum/total_batches))\n",
        "    #epoch_losses = np.array([loss_D_sum/totalbatches], [loss_G_fake_sum/total_batches], [loss_perturb_sum/totalbatches], [loss_adv_sum/total_batches])\n",
        "\t\t#np.savetxt(\"epoch_{}_losses.txt\".format(epoch), epoch_losses, delimiter=',')\n",
        "    \n",
        "        if epoch % 10 == 0:\n",
        "            g_saver.save(sess, \"weights/generator/gen\")\n",
        "            d_saver.save(sess, \"weights/discriminator/disc\")\n",
        "\n",
        "    # evaluate the test set\n",
        "    correct_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    accs = []\n",
        "    total_batches_test = int(X_test.shape[0] / batch_size)\n",
        "    for i in range(total_batches_test):\n",
        "        batch_x, batch_y = next_batch(X_test, y_test, i, batch_size)\n",
        "        acc, x_pert = sess.run([accuracy, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "        accs.append(acc)\n",
        "\n",
        "    print('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "  #test_acc = np.array(sum(accs)/len(accs))\n",
        "  #np.savetxt(\"test_accuracy_GD.txt\", test_acc, delimiter=',')\n",
        "\n",
        "\t# plot some images and their perturbed counterparts\n",
        "    f, axarr = plt.subplots(2,2)\n",
        "    axarr[0,0].imshow(np.squeeze(batch_x[2]), cmap='Greys_r')\n",
        "    axarr[0,1].imshow(np.squeeze(x_pert[2]), cmap='Greys_r')\n",
        "    axarr[1,0].imshow(np.squeeze(batch_x[5]), cmap='Greys_r')\n",
        "    axarr[1,1].imshow(np.squeeze(x_pert[5]), cmap='Greys_r')\n",
        "    plt.show()\n",
        "\n",
        "    print('finished training, saving weights')\n",
        "    g_saver.save(sess, \"weights/generator/gen\")\n",
        "    d_saver.save(sess, \"weights/discriminator/disc\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def attack(X, y, batch_size=128, thresh=0.3, target=3):\n",
        "    x_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "    t = tf.placeholder(tf.float32, [None, 43]) # target placeholder\n",
        "    is_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "    is_targeted = False\n",
        "    if target in range(0, 43):\n",
        "        is_targeted = True\n",
        "\n",
        "    perturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "    x_perturbed = perturb + x_pl\n",
        "    x_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "\n",
        "    f = Target()\n",
        "    f_real_logits, f_real_probs = f.Model(x_pl)\n",
        "    f_fake_logits, f_fake_probs = f.Model(x_perturbed)\n",
        "\n",
        "    t_vars = tf.trainable_variables()\n",
        "    f_vars = [var for var in t_vars if 'Model' in var.name]\n",
        "    g_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "    sess = tf.Session()\n",
        "\n",
        "    f_saver = tf.train.Saver(f_vars)\n",
        "    g_saver = tf.train.Saver(g_vars)\n",
        "    f_saver.restore(sess, \"./weights/target_model/model\")\n",
        "    g_saver.restore(sess, tf.train.latest_checkpoint(\"./weights/generator/\"))\n",
        "\n",
        "    rawpert, pert, fake_l, real_l = sess.run([perturb, x_perturbed, f_fake_probs, f_real_probs], \\\n",
        "                          feed_dict={x_pl: X[:32], \\\n",
        "                                 is_training: False})\n",
        "    print('LA: ' + str(np.argmax(y[:32], axis=1)))\n",
        "    print('OG: ' + str(np.argmax(real_l, axis=1)))\n",
        "    print('PB: ' + str(np.argmax(fake_l, axis=1)))\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    accs = []\n",
        "    total_batches_test = int(X.shape[0] / batch_size)\n",
        "    for i in range(total_batches_test):\n",
        "        batch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "        if is_targeted:\n",
        "            targets = np.full((batch_y.shape[0],), target)\n",
        "            batch_y = np.eye(43)[targets]\n",
        "\n",
        "        acc, fake_l, x_pert = sess.run([accuracy, f_fake_probs, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "        accs.append(acc)\n",
        "\n",
        "    print('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "\n",
        "    f, axarr = plt.subplots(2,2)\n",
        "    axarr[0,0].imshow(np.squeeze(X[3]), cmap='Greys_r')\n",
        "    axarr[0,1].imshow(np.squeeze(pert[3]), cmap='Greys_r')\n",
        "    axarr[1,0].imshow(np.squeeze(X[4]), cmap='Greys_r')\n",
        "    axarr[1,1].imshow(np.squeeze(pert[4]), cmap='Greys_r')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "'''\n",
        "import pickle\n",
        "\n",
        "training_file = 'train.p'\n",
        "testing_file = 'test.p'\n",
        "validation_file = 'valid.p'\n",
        "\n",
        "with open(training_file, mode='rb') as f:\n",
        "    tstrain = pickle.load(f)\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    tstest = pickle.load(f)\n",
        "with open(validation_file, mode='rb') as f:\n",
        "    tsvalid = pickle.load(f)\n",
        "\n",
        "X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "#shuffle training set\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "#grayscale images\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "X_valid = np.dot(X_valid, grayscale)\n",
        "\n",
        "\n",
        "#normalize\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "X_valid = np.array(X_valid)/255\n",
        "\n",
        "#expand dimensions to fit 4D input array\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "X_valid = np.expand_dims(X_valid,-1)\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "'''\n",
        "AdvGAN(X_train, Y_train, X_test, Y_test, batch_size=128, epochs=50, target=-1)\n",
        "attack(X_test, Y_test, target=-1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y shape\n",
            "(34799,)\n",
            "y_test shape\n",
            "(12630,)\n",
            "t shape)\n",
            "(?, 43)\n",
            "WARNING:tensorflow:From <ipython-input-3-7ad6c5787705>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-3-7ad6c5787705>:48: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-7ad6c5787705>:31: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d_transpose instead.\n",
            "(?, 32, 32, 1)\n",
            "WARNING:tensorflow:From <ipython-input-4-85d97f4f431c>:44: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-85d97f4f431c>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "(?, 1)\n",
            "(?, 43)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./weights/target_model/model\n",
            "Pretrained model loaded\n",
            "(128, 32, 32, 1)\n",
            "(128,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-957fba5a9d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m '''\n\u001b[0;32m--> 320\u001b[0;31m \u001b[0mAdvGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-957fba5a9d32>\u001b[0m in \u001b[0;36mAdvGAN\u001b[0;34m(X, y, X_test, y_test, epochs, batch_size, target)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_G_fake_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_adv_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_perturb_batch\u001b[0m \u001b[0;34m=\u001b[0m                         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_perturb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mloss_D_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_D_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mloss_G_fake_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_G_fake_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (128,) for Tensor 'Placeholder_5:0', which has shape '(?, 43)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQZTHyxsKU2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tb"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fullGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/fullGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABnslutLuWVE",
        "colab_type": "code",
        "outputId": "2eacd202-1554-4a3a-80d5-83b697255e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!mkdir weights\n",
        "!mkdir weights/target_model\n",
        "!mkdir weights/generator\n",
        "!mkdir weights/discriminator\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘weights’: File exists\n",
            "mkdir: cannot create directory ‘weights/target_model’: File exists\n",
            "mkdir: cannot create directory ‘weights/generator’: File exists\n",
            "mkdir: cannot create directory ‘weights/discriminator’: File exists\n",
            "sample_data  test.p  train.p  valid.p  weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-dNiamCtfBr",
        "colab_type": "code",
        "outputId": "e8a51e46-820b-4f3c-8c40-65a294a65c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1318
        }
      },
      "source": [
        "#TARGET CLASSIFIER\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1187) #to help reproduce\n",
        "\n",
        "#from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "#import random\n",
        "#import cv2\n",
        "#from skimage.filters import rank\n",
        "#import skimage.morphology as morp\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#from keras.utils import to_categorical\n",
        "#from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "#from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "\n",
        "class Target:\n",
        "    def __init__(self, lr=0.001, epochs=25, n_input=32, n_classes=43, batch_size=20, restore=0):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.n_input = 32\n",
        "        self.n_classes = 43\n",
        "        self.batch_size = batch_size\n",
        "        self.restore = restore\n",
        "\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    \n",
        "    '''\n",
        "    def next_batch(self, X, Y, i, batch_size):\n",
        "      idx = i*batch_size\n",
        "      idx_n = idx + batch_size\n",
        "      return X[idx:idx_n], Y[idx:idx_n]\n",
        "      '''\n",
        "    \n",
        "    def Model(self, x):\n",
        "        with tf.variable_scope('Model', reuse=tf.AUTO_REUSE):\n",
        "            # Hyperparameters\n",
        "            mu = 0\n",
        "            sigma = 0.1\n",
        "            n_out = self.n_classes\n",
        "            learning_rate = self.lr\n",
        "\n",
        "            # Layer 1 (Convolutional): Input = 32x32x1. Output = 28x28x6.\n",
        "            filter1_width = 5\n",
        "            filter1_height = 5\n",
        "            input1_channels = 1\n",
        "            conv1_output = 6\n",
        "            # Weight and bias\n",
        "            conv1_weight = tf.Variable(tf.truncated_normal(\n",
        "                shape=(filter1_width, filter1_height, input1_channels, conv1_output),\n",
        "                mean = mu, stddev = sigma))\n",
        "            conv1_bias = tf.Variable(tf.zeros(conv1_output))\n",
        "\n",
        "            # Apply Convolution\n",
        "            conv1 = tf.nn.conv2d(x, conv1_weight, strides=[1, 1, 1, 1], padding='VALID') + conv1_bias\n",
        "\n",
        "            # Activation:\n",
        "            conv1 = tf.nn.relu(conv1)\n",
        "\n",
        "            # Pooling: Input = 28x28x6. Output = 14x14x6.\n",
        "            conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "\n",
        "            # Layer 2 (Convolutional): Output = 10x10x16.\n",
        "            filter2_width = 5\n",
        "            filter2_height = 5\n",
        "            input2_channels = 6\n",
        "            conv2_output = 16\n",
        "            # Weight and bias\n",
        "            conv2_weight = tf.Variable(tf.truncated_normal(\n",
        "                shape=(filter2_width, filter2_height, input2_channels, conv2_output),\n",
        "                mean = mu, stddev = sigma))\n",
        "            conv2_bias = tf.Variable(tf.zeros(conv2_output))\n",
        "\n",
        "            # Apply Convolution\n",
        "            conv2 = tf.nn.conv2d(conv1, conv2_weight, strides=[1, 1, 1, 1], padding='VALID') + conv2_bias\n",
        "\n",
        "            # Activation:\n",
        "            conv2 = tf.nn.relu(conv2)\n",
        "\n",
        "            # Pooling: Input = 10x10x16. Output = 5x5x16.\n",
        "            conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "\n",
        "            # Flattening: Input = 5x5x16. Output = 400.\n",
        "            fully_connected0 = Flatten()(conv2)\n",
        "\n",
        "            # Layer 3 (Fully Connected): Input = 400. Output = 120.\n",
        "            connected1_weights = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
        "            connected1_bias = tf.Variable(tf.zeros(120))\n",
        "            fully_connected1 = tf.add((tf.matmul(fully_connected0, connected1_weights)), connected1_bias)\n",
        "\n",
        "            # Activation:\n",
        "            fully_connected1 = tf.nn.relu(fully_connected1)\n",
        "\n",
        "            # Layer 4 (Fully Connected): Input = 120. Output = 84.\n",
        "            connected2_weights = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
        "            connected2_bias = tf.Variable(tf.zeros(84))\n",
        "            fully_connected2 = tf.add((tf.matmul(fully_connected1, connected2_weights)), connected2_bias)\n",
        "\n",
        "            # Activation.\n",
        "            fully_connected2 = tf.nn.relu(fully_connected2)\n",
        "    \n",
        "            # Layer 5 (Fully Connected): Input = 84. Output = 43.\n",
        "            output_weights = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
        "            output_bias = tf.Variable(tf.zeros(43))\n",
        "            logits =  tf.add((tf.matmul(fully_connected2, output_weights)), output_bias)\n",
        "\n",
        "            probs = tf.nn.sigmoid(logits)\n",
        "            \n",
        "            return logits, probs\n",
        "    \n",
        "    \n",
        "    \n",
        "    def test(self, X_data, BATCH_SIZE=64):\n",
        "        num_examples = len(X_data)\n",
        "        y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "        sess = tf.get_default_session()\n",
        "        for offset in range(0, num_examples, BATCH_SIZE):\n",
        "            batch_x = X_data[offset:offset+BATCH_SIZE]\n",
        "            y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(logits, 1), \n",
        "                               feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "        return y_pred\n",
        "    \n",
        "    \n",
        "    def train(self, X_train, Y_train, X_valid, Y_valid):\n",
        "        #placeholders for inputs\n",
        "        x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
        "        y = tf.placeholder(tf.int32, (None))\n",
        "\n",
        "        keep_prob = tf.placeholder(tf.float32)       # For fully-connected layers\n",
        "        keep_prob_conv = tf.placeholder(tf.float32)\n",
        "\n",
        "        #define graph\n",
        "        logits, _ = self.Model(x)\n",
        "        \n",
        "              # Training operation\n",
        "        one_hot_y = tf.one_hot(y, 43)\n",
        "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=one_hot_y)\n",
        "        loss_operation = tf.reduce_mean(cross_entropy)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate = self.lr)\n",
        "        training_operation = optimizer.minimize(loss_operation)\n",
        "\n",
        "        # Accuracy operation\n",
        "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
        "        accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "          # Saving all variables\n",
        "        saver = tf.train.Saver()\n",
        "\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            num_train = len(Y_train)\n",
        "            num_valid = len(Y_valid)\n",
        "            print(\"Training ...\")\n",
        "            print()\n",
        "            EPOCHS = self.epochs\n",
        "            BATCH_SIZE = self.batch_size\n",
        "            DIR = \"./weights/target_model\"\n",
        "            total_batch = int(X_train.shape[0] / self.batch_size)\n",
        "\n",
        "            for i in range(EPOCHS):\n",
        "                avg_cost = 0.\n",
        "                total_accuracy = 0\n",
        "                validation_accuracy = 0\n",
        "                #Train set\n",
        "                for offset in range(0, num_train, BATCH_SIZE):\n",
        "                    end = offset + BATCH_SIZE\n",
        "                    batch_x, batch_y = X_train[offset:end], Y_train[offset:end]\n",
        "                    _, c = sess.run([training_operation, loss_operation], feed_dict={x: batch_x, y: batch_y, keep_prob : 0.6, keep_prob_conv: 0.8})\n",
        "                    avg_cost += c / total_batch\n",
        "                    \n",
        "                    #Validation Set\n",
        "                for offset in range(0, num_valid, BATCH_SIZE):\n",
        "                    end = offset + BATCH_SIZE\n",
        "                    batch_x, batch_y = X_valid[offset:end], Y_valid[offset:end]\n",
        "                    accuracy = sess.run(accuracy_operation, \n",
        "                                    feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0, keep_prob_conv: 1.0 })\n",
        "                    total_accuracy += (accuracy * len(batch_x))\n",
        "                    validation_accuracy = total_accuracy / num_valid\n",
        "                    #print(\"Validation Accuracy = {:.3f}%\".format(validation_accuracy*100))\n",
        "                    \n",
        "                print(\"Epoch: \", '%04d' % (i+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
        "                print(\"EPOCH {} : Validation Accuracy = {:.3f}%\".format(i+1, (validation_accuracy*100)))\n",
        "            \n",
        "            \n",
        "            #Test set\n",
        "            num_examples = len(X_test)\n",
        "            y_pred = np.zeros(num_examples, dtype=np.int32)\n",
        "            #sess = tf.get_default_session()\n",
        "            for offset in range(0, num_examples, BATCH_SIZE):\n",
        "                batch_x = X_test[offset:offset+BATCH_SIZE]\n",
        "                y_pred[offset:offset+BATCH_SIZE] = sess.run(tf.argmax(logits, 1), \n",
        "                                   feed_dict={x:batch_x, keep_prob:1, keep_prob_conv:1})\n",
        "            test_accuracy = sum(Y_test == y_pred)/len(Y_test)\n",
        "            print(\"Test Accuracy = {:.1f}%\".format(test_accuracy*100))\n",
        "\n",
        "            cm = confusion_matrix(Y_test, y_pred)\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cm = np.log(.0001 + cm)\n",
        "            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "            plt.title('Log of normalized Confusion Matrix')\n",
        "            plt.ylabel('True label')\n",
        "            plt.xlabel('Predicted label')\n",
        "            plt.show()\n",
        "            \n",
        "            saver.save(sess, \"./weights/target_model/model\")\n",
        "            print(\"Model saved\")\n",
        "            sess.close()\n",
        "\n",
        "   \n",
        "      \n",
        "      \n",
        "import pickle\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    training_file = 'train.p'\n",
        "    testing_file = 'test.p'\n",
        "    validation_file = 'valid.p'\n",
        "\n",
        "    with open(training_file, mode='rb') as f:\n",
        "        tstrain = pickle.load(f)\n",
        "    with open(testing_file, mode='rb') as f:\n",
        "        tstest = pickle.load(f)\n",
        "    with open(validation_file, mode='rb') as f:\n",
        "        tsvalid = pickle.load(f)\n",
        "\n",
        "    X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "    X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "    X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "    #shuffle training set\n",
        "    X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "    #grayscale images\n",
        "    grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "    X_test = np.dot(X_test, grayscale)\n",
        "    X_train = np.dot(X_train, grayscale)\n",
        "    X_valid = np.dot(X_valid, grayscale)\n",
        "\n",
        "\n",
        "    #normalize\n",
        "    X_train = np.array(X_train)/255\n",
        "    X_test = np.array(X_test)/255\n",
        "    X_valid = np.array(X_valid)/255\n",
        "\n",
        "    #expand dimensions to fit 4D input array\n",
        "    X_train = np.expand_dims(X_train,-1)\n",
        "    X_test = np.expand_dims(X_test,-1)\n",
        "    X_valid = np.expand_dims(X_valid,-1)\n",
        "\n",
        "    assert(len(X_train)==len(Y_train))\n",
        "    n_train = len(X_train)\n",
        "    assert(len(X_test)==len(Y_test))\n",
        "    n_test = len(X_test)\n",
        "\n",
        "    cnn = Target()\n",
        "    cnn.train(X_train, Y_train, X_valid, Y_valid)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Training ...\n",
            "\n",
            "Epoch:  0001 cost= 1.143467917\n",
            "EPOCH 1 : Validation Accuracy = 85.306%\n",
            "Epoch:  0002 cost= 0.259472334\n",
            "EPOCH 2 : Validation Accuracy = 89.433%\n",
            "Epoch:  0003 cost= 0.146756447\n",
            "EPOCH 3 : Validation Accuracy = 91.383%\n",
            "Epoch:  0004 cost= 0.096168410\n",
            "EPOCH 4 : Validation Accuracy = 90.000%\n",
            "Epoch:  0005 cost= 0.072873450\n",
            "EPOCH 5 : Validation Accuracy = 92.222%\n",
            "Epoch:  0006 cost= 0.057228964\n",
            "EPOCH 6 : Validation Accuracy = 91.769%\n",
            "Epoch:  0007 cost= 0.049171635\n",
            "EPOCH 7 : Validation Accuracy = 92.948%\n",
            "Epoch:  0008 cost= 0.036925727\n",
            "EPOCH 8 : Validation Accuracy = 91.814%\n",
            "Epoch:  0009 cost= 0.033298687\n",
            "EPOCH 9 : Validation Accuracy = 92.290%\n",
            "Epoch:  0010 cost= 0.029385127\n",
            "EPOCH 10 : Validation Accuracy = 90.454%\n",
            "Epoch:  0011 cost= 0.026538879\n",
            "EPOCH 11 : Validation Accuracy = 91.814%\n",
            "Epoch:  0012 cost= 0.026469827\n",
            "EPOCH 12 : Validation Accuracy = 90.680%\n",
            "Epoch:  0013 cost= 0.023299567\n",
            "EPOCH 13 : Validation Accuracy = 92.245%\n",
            "Epoch:  0014 cost= 0.020261788\n",
            "EPOCH 14 : Validation Accuracy = 91.406%\n",
            "Epoch:  0015 cost= 0.024069453\n",
            "EPOCH 15 : Validation Accuracy = 92.925%\n",
            "Epoch:  0016 cost= 0.016160478\n",
            "EPOCH 16 : Validation Accuracy = 93.152%\n",
            "Epoch:  0017 cost= 0.020125889\n",
            "EPOCH 17 : Validation Accuracy = 93.537%\n",
            "Epoch:  0018 cost= 0.018506469\n",
            "EPOCH 18 : Validation Accuracy = 94.739%\n",
            "Epoch:  0019 cost= 0.010660831\n",
            "EPOCH 19 : Validation Accuracy = 93.673%\n",
            "Epoch:  0020 cost= 0.015504620\n",
            "EPOCH 20 : Validation Accuracy = 92.132%\n",
            "Epoch:  0021 cost= 0.017784293\n",
            "EPOCH 21 : Validation Accuracy = 94.399%\n",
            "Epoch:  0022 cost= 0.013004571\n",
            "EPOCH 22 : Validation Accuracy = 94.331%\n",
            "Epoch:  0023 cost= 0.014552169\n",
            "EPOCH 23 : Validation Accuracy = 93.946%\n",
            "Epoch:  0024 cost= 0.017063509\n",
            "EPOCH 24 : Validation Accuracy = 91.746%\n",
            "Epoch:  0025 cost= 0.009959780\n",
            "EPOCH 25 : Validation Accuracy = 94.082%\n",
            "Test Accuracy = 92.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAEWCAYAAAB8A8JQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXDxpOOdy8aThnMvFk4ZzLpf/D0flxWm2LhpyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2laXHD7-tmk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generator\n",
        "'''\n",
        "\tGenerator definition for AdvGAN\n",
        "\tref: https://arxiv.org/pdf/1801.02610.pdf\n",
        "'''\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from keras import layers\n",
        "\n",
        "# helper function for convolution -> instance norm -> relu\n",
        "def ConvInstNormRelu(x, filters, kernel_size=3, strides=1):\n",
        "\tConv = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tInstNorm = tf.contrib.layers.instance_norm(Conv)\n",
        "\n",
        "\treturn tf.nn.relu(InstNorm)\n",
        "\n",
        "\n",
        "# helper function for trans convolution -> instance norm -> relu\n",
        "def TransConvInstNormRelu(x, filters, kernel_size=3, strides=2):\n",
        "\tTransConv = tf.layers.conv2d_transpose(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tInstNorm = tf.contrib.layers.instance_norm(TransConv)\n",
        "\n",
        "\treturn tf.nn.relu(InstNorm)\n",
        "\n",
        "# helper function for residual block of 2 convolutions with same num filters\n",
        "# in the same style as ConvInstNormRelu\n",
        "def ResBlock(x, training, filters=32, kernel_size=3, strides=1):\n",
        "\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tconv1_norm = tf.layers.batch_normalization(conv1, training=training)\n",
        "\n",
        "\tconv1_relu = tf.nn.relu(conv1_norm)\n",
        "\n",
        "\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=conv1_relu,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tconv2_norm = tf.layers.batch_normalization(conv2, training=training)\n",
        "\n",
        "\n",
        "\treturn x + conv2_norm\n",
        "\n",
        "\n",
        "def generator(x, training):\n",
        "\twith tf.variable_scope('g_weights', reuse=tf.AUTO_REUSE): #True\n",
        "\t\t# input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\t# define first three conv + inst + relu layers\n",
        "\t\tc1 = ConvInstNormRelu(x, filters=8, kernel_size=3, strides=1)\n",
        "\t\td1 = ConvInstNormRelu(c1, filters=16, kernel_size=3, strides=2)\n",
        "\t\td2 = ConvInstNormRelu(d1, filters=32, kernel_size=3, strides=2)\n",
        "\n",
        "\t\t# define residual blocks\n",
        "\t\trb1 = ResBlock(d2, training, filters=32)\n",
        "\t\trb2 = ResBlock(rb1, training, filters=32)\n",
        "\t\trb3 = ResBlock(rb2, training, filters=32)\n",
        "\t\trb4 = ResBlock(rb3, training, filters=32)\n",
        "\n",
        "\t\t# upsample using conv transpose\n",
        "\t\tu1 = TransConvInstNormRelu(rb4, filters=16, kernel_size=3, strides=2)\n",
        "\t\tu2 = TransConvInstNormRelu(u1, filters=8, kernel_size=3, strides=2)\n",
        "\n",
        "\t\t# final layer block\n",
        "\t\tout = tf.layers.conv2d_transpose(\n",
        "\t\t\t\t\t\tinputs=u2,\n",
        "\t\t\t\t\t\tfilters=x.get_shape()[-1].value, # or 3 if RGB image\n",
        "\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\tstrides=1,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\t# out = tf.contrib.layers.instance_norm(out)\n",
        "\n",
        "\t\treturn tf.nn.tanh(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKYLa86WtyLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Discriminator\n",
        "'''\n",
        "\tDiscriminator definition for AdvGAN\n",
        "\tref: https://arxiv.org/pdf/1801.02610.pdf\n",
        "'''\n",
        "\n",
        "#import tensorflow as tf\n",
        "\n",
        "def discriminator(x, training):\n",
        "\twith tf.variable_scope('d_weights', reuse=tf.AUTO_REUSE):\n",
        "\t\t# input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\t\tfilters=8,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\t\tconv1 = tf.nn.leaky_relu(conv1, alpha=0.2)\n",
        "\n",
        "\t\t\n",
        "\t\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=conv1,\n",
        "\t\t\t\t\t\t\tfilters=16,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\tin1 = tf.contrib.layers.instance_norm(conv2)\n",
        "\t\tconv2 = tf.nn.leaky_relu(in1, alpha=0.2)\n",
        "\n",
        "\t\tconv3 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=conv2,\n",
        "\t\t\t\t\t\t\tfilters=32,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\t#in2 = tf.contrib.layers.instance_norm(conv3)\n",
        "\t\tin2 = tf.contrib.layers.instance_norm(conv3)\n",
        "\t\tconv3 = tf.nn.leaky_relu(in2, alpha=0.2)\n",
        "\t\tflat = tf.layers.flatten(conv3)\n",
        "\t\tlogits = tf.layers.dense(flat, 1)\n",
        "\n",
        "\t\tprobs = tf.nn.sigmoid(logits)\n",
        "\n",
        "\t\treturn logits, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "288LCGWawCVl",
        "colab_type": "code",
        "outputId": "c94fcd2e-ab2e-4310-9a2b-7b559310267c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os, sys\n",
        "import random\n",
        "\n",
        "#make sure GAN_setup.py is in connected folder\n",
        "#from GAN_setup import generator, discriminator\n",
        "\n",
        "#ctargon created class Target and defined/trained his target model in there, then called here\n",
        "#import Target as target_model\n",
        "\n",
        "\n",
        "# get the next batch based on x, y, and the iteration (based on batch_size)\n",
        "def next_batch(X, Y, i, batch_size):\n",
        "    idx = i * batch_size\n",
        "    idx_n = i * batch_size + batch_size\n",
        "    return X[idx:idx_n], Y[idx:idx_n]\n",
        "\n",
        "# loss function to encourage misclassification after perturbation\n",
        "def adv_loss(preds, labels, is_targeted):\n",
        "    real = tf.reduce_sum(labels * preds, 1)\n",
        "    other = tf.reduce_max((1 - labels) * preds - (labels * 10000), 1)\n",
        "    if is_targeted:\n",
        "        return tf.reduce_sum(tf.maximum(0.0, other - real))\n",
        "    return tf.reduce_sum(tf.maximum(0.0, real - other))\n",
        "\n",
        "# loss function to influence the perturbation to be as close to 0 as possible\n",
        "def perturb_loss(preds, thresh=0.3):\n",
        "    zeros = tf.zeros((tf.shape(preds)[0]))\n",
        "    return tf.reduce_mean(tf.maximum(zeros, tf.norm(tf.reshape(preds, (tf.shape(preds)[0], -1)), axis=1) - thresh))\n",
        "\n",
        "\n",
        "# function that defines ops, graphs, and training procedure for AdvGAN framework\n",
        "def AdvGAN(X, y, X_test, y_test, epochs=50, batch_size=128, target=3):\n",
        "    #print(X_train.shape)\n",
        "    #print(y.shape[-1]) is num_images\n",
        "    print(\"y shape\")\n",
        "    print(y.shape)\n",
        "    print(\"y_test shape\")\n",
        "    print(y_test.shape)\n",
        "    \n",
        "    # placeholder definitions\n",
        "    x_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "    t = tf.placeholder(tf.float32, [None, y.shape[-1]]) # target placeholder\n",
        "    print(\"t shape)\")\n",
        "    print(t.shape)\n",
        "    is_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "    #-----------------------------------------------------------------------------------\n",
        "    # MODEL DEFINITIONS\n",
        "    is_targeted = False\n",
        "    if target in range(0, y.shape[-1]):\n",
        "        is_targeted = True\n",
        "\n",
        "    # gather target model\n",
        "    f = Target()\n",
        "    print(\"is targeted boolean\")\n",
        "    print(is_targeted)\n",
        "    \n",
        "    thresh = 0.3\n",
        "\n",
        "    # generate perturbation, add to original input image(s)\n",
        "    perturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "    x_perturbed = perturb + x_pl\n",
        "    x_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "    print(x_perturbed.shape)\n",
        "\n",
        "    # pass real and perturbed image to discriminator and the target model\n",
        "    d_real_logits, d_real_probs = discriminator(x_pl, is_training)\n",
        "    d_fake_logits, d_fake_probs = discriminator(x_perturbed, is_training)\n",
        "    print(d_fake_probs.shape)#1\n",
        "    # pass real and perturbed images to the model we are trying to fool\n",
        "    f_real_logits, f_real_probs = f.Model(x_pl)\n",
        "    f_fake_logits, f_fake_probs = f.Model(x_perturbed)\n",
        "    print(f_fake_probs.shape) #43\n",
        "\n",
        "    # generate labels for discriminator (optionally smooth labels for stability)\n",
        "    smooth = 0.0\n",
        "    d_labels_real = tf.ones_like(d_real_probs) * (1 - smooth)\n",
        "    d_labels_fake = tf.zeros_like(d_fake_probs)\n",
        "\n",
        "    #-----------------------------------------------------------------------------------\n",
        "    # LOSS DEFINITIONS\n",
        "    # discriminator loss\n",
        "    d_loss_real = tf.losses.mean_squared_error(predictions=d_real_probs, labels=d_labels_real)\n",
        "    d_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=d_labels_fake)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    # generator loss\n",
        "    g_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=tf.ones_like(d_fake_probs))\n",
        "\n",
        "    # perturbation loss (minimize overall perturbation)\n",
        "    l_perturb = perturb_loss(perturb, thresh)\n",
        "\n",
        "    # adversarial loss (encourage misclassification)\n",
        "    l_adv = adv_loss(f_fake_probs, t, is_targeted)\n",
        "\n",
        "    # weights for generator loss function\n",
        "    alpha = 1.0\n",
        "    beta = 5.0\n",
        "    g_loss = l_adv + alpha*g_loss_fake + beta*l_perturb \n",
        "\n",
        "    # ----------------------------------------------------------------------------------\n",
        "    # gather variables for training/restoring\n",
        "    t_vars = tf.trainable_variables()\n",
        "    f_vars = [var for var in t_vars if 'Model' in var.name]\n",
        "    d_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "    g_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "    # define optimizers for discriminator and generator\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        d_opt = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n",
        "        g_opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "\t# create saver objects for the target model, generator, and discriminator\n",
        "    saver = tf.train.Saver(f_vars)\n",
        "    g_saver = tf.train.Saver(g_vars)\n",
        "    d_saver = tf.train.Saver(d_vars)\n",
        "\n",
        "    init  = tf.global_variables_initializer()\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    sess.run(init)\n",
        "    \n",
        "    # load the pretrained target model\n",
        "    #try:\n",
        "       # saver.restore(sess, \"./weights/target_model/model\")\n",
        "    #except:\n",
        "       # print(\"make sure to train the target model first...\")\n",
        "       # sys.exit(1)\n",
        "\n",
        "    \n",
        "    new_saver = tf.train.import_meta_graph('./weights/target_model/model.meta')\n",
        "    new_saver.restore(sess, tf.train.latest_checkpoint('./weights/target_model'))\n",
        "    #path_to_ckpt_data = './weights/target_model/model.data-00000-of-00001'\n",
        "    #new_saver.restore(sess, path_to_ckpt_data)\n",
        "    \n",
        "    print(\"Pretrained model loaded\")\n",
        "    \n",
        "    total_batches = int(X.shape[0] / batch_size)\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        loss_D_sum = 0.0\n",
        "        loss_G_fake_sum = 0.0\n",
        "        loss_perturb_sum = 0.0\n",
        "        loss_adv_sum = 0.0\n",
        "\n",
        "        for i in range(total_batches):\n",
        "\n",
        "            batch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "            # if targeted, create one hot vectors of the target\n",
        "            if is_targeted:\n",
        "                targets = np.full((batch_y.shape[0],), target)\n",
        "                batch_y = np.eye(y.shape[-1])[targets]\n",
        "\n",
        "            # train the discriminator first n times\n",
        "            for _ in range(1):\n",
        "                _, loss_D_batch = sess.run([d_opt, d_loss], feed_dict={x_pl: batch_x, \\\n",
        "                                           is_training: True})\n",
        "\n",
        "            #print(\"batch x\")\n",
        "            #print(batch_x.shape)\n",
        "            #print(\"batch y\")\n",
        "            #print(batch_y.shape)\n",
        "            \n",
        "\t\t\t       # train the generator n times\n",
        "            for _ in range(1):\n",
        "                \n",
        "                _, loss_G_fake_batch, loss_adv_batch, loss_perturb_batch = \\\n",
        "                        sess.run([g_opt, g_loss_fake, l_adv, l_perturb], \\\n",
        "                              feed_dict={x_pl: batch_x, \\\n",
        "                                     t: batch_y, \\\n",
        "                                     is_training: True})\n",
        "            loss_D_sum += loss_D_batch\n",
        "            loss_G_fake_sum += loss_G_fake_batch\n",
        "            loss_perturb_sum += loss_perturb_batch\n",
        "            loss_adv_sum += loss_adv_batch\n",
        "\n",
        "        print(\"epoch %d:\\nloss_D: %.3f, loss_G_fake: %.3f, \\\n",
        "            \\nloss_perturb: %.3f, loss_adv: %.3f, \\n\" %\n",
        "            (epoch + 1, loss_D_sum/total_batches, loss_G_fake_sum/total_batches,\n",
        "            loss_perturb_sum/total_batches, loss_adv_sum/total_batches))\n",
        "    #epoch_losses = np.array([loss_D_sum/totalbatches], [loss_G_fake_sum/total_batches], [loss_perturb_sum/totalbatches], [loss_adv_sum/total_batches])\n",
        "\t\t#np.savetxt(\"epoch_{}_losses.txt\".format(epoch), epoch_losses, delimiter=',')\n",
        "    \n",
        "        if epoch % 10 == 0:\n",
        "            g_saver.save(sess, \"weights/generator/gen\")\n",
        "            d_saver.save(sess, \"weights/discriminator/disc\")\n",
        "\n",
        "    # evaluate the test set\n",
        "    correct_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    accs = []\n",
        "    total_batches_test = int(X_test.shape[0] / batch_size)\n",
        "    for i in range(total_batches_test):\n",
        "        batch_x, batch_y = next_batch(X_test, y_test, i, batch_size)\n",
        "        acc, x_pert = sess.run([accuracy, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "        accs.append(acc)\n",
        "\n",
        "    print('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "  #test_acc = np.array(sum(accs)/len(accs))\n",
        "  #np.savetxt(\"test_accuracy_GD.txt\", test_acc, delimiter=',')\n",
        "\n",
        "\t# plot some images and their perturbed counterparts\n",
        "    f, axarr = plt.subplots(2,2)\n",
        "    axarr[0,0].imshow(np.squeeze(batch_x[2]), cmap='Greys_r')\n",
        "    axarr[0,1].imshow(np.squeeze(x_pert[2]), cmap='Greys_r')\n",
        "    axarr[1,0].imshow(np.squeeze(batch_x[5]), cmap='Greys_r')\n",
        "    axarr[1,1].imshow(np.squeeze(x_pert[5]), cmap='Greys_r')\n",
        "    plt.show()\n",
        "\n",
        "    print('finished training, saving weights')\n",
        "    g_saver.save(sess, \"weights/generator/gen\")\n",
        "    d_saver.save(sess, \"weights/discriminator/disc\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def attack(X, y, batch_size=128, thresh=0.3, target=3):\n",
        "    x_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "    t = tf.placeholder(tf.float32, [None, y.shape[-1]]) # target placeholder\n",
        "    is_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "    is_targeted = False\n",
        "    if target in range(0, y.shape[-1]):\n",
        "        is_targeted = True\n",
        "\n",
        "    perturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "    x_perturbed = perturb + x_pl\n",
        "    x_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "\n",
        "    f = Target()\n",
        "    f_real_logits, f_real_probs = f.Model(x_pl)\n",
        "    f_fake_logits, f_fake_probs = f.Model(x_perturbed)\n",
        "\n",
        "    t_vars = tf.trainable_variables()\n",
        "    f_vars = [var for var in t_vars if 'Model' in var.name]\n",
        "    g_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "    sess = tf.Session()\n",
        "\n",
        "    f_saver2 = tf.train.Saver(f_vars)\n",
        "    g_saver2 = tf.train.Saver(g_vars)\n",
        "    f_saver2.restore(sess, \"./weights/target_model/model\")\n",
        "    g_saver2.restore(sess, tf.train.latest_checkpoint(\"./weights/generator/\"))\n",
        "\n",
        "    rawpert, pert, fake_l, real_l = sess.run([perturb, x_perturbed, f_fake_probs, f_real_probs], \\\n",
        "                          feed_dict={x_pl: X[:32], \\\n",
        "                                 is_training: False})\n",
        "    print('LA: ' + str(np.argmax(y[:32], axis=1)))\n",
        "    print('OG: ' + str(np.argmax(real_l, axis=1)))\n",
        "    print('PB: ' + str(np.argmax(fake_l, axis=1)))\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    accs = []\n",
        "    total_batches_test = int(X.shape[0] / batch_size)\n",
        "    for i in range(total_batches_test):\n",
        "        batch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "        if is_targeted:\n",
        "            targets = np.full((batch_y.shape[0],), target)\n",
        "            batch_y = np.eye(y.shape[-1])[targets]\n",
        "\n",
        "        acc, fake_l, x_pert = sess.run([accuracy, f_fake_probs, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "        accs.append(acc)\n",
        "\n",
        "    print('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "\n",
        "    f, axarr = plt.subplots(2,2)\n",
        "    axarr[0,0].imshow(np.squeeze(X[3]), cmap='Greys_r')\n",
        "    axarr[0,1].imshow(np.squeeze(pert[3]), cmap='Greys_r')\n",
        "    axarr[1,0].imshow(np.squeeze(X[4]), cmap='Greys_r')\n",
        "    axarr[1,1].imshow(np.squeeze(pert[4]), cmap='Greys_r')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "'''\n",
        "import pickle\n",
        "\n",
        "training_file = 'train.p'\n",
        "testing_file = 'test.p'\n",
        "validation_file = 'valid.p'\n",
        "\n",
        "with open(training_file, mode='rb') as f:\n",
        "    tstrain = pickle.load(f)\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    tstest = pickle.load(f)\n",
        "with open(validation_file, mode='rb') as f:\n",
        "    tsvalid = pickle.load(f)\n",
        "\n",
        "X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "#shuffle training set\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "#grayscale images\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "X_valid = np.dot(X_valid, grayscale)\n",
        "\n",
        "\n",
        "#normalize\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "X_valid = np.array(X_valid)/255\n",
        "\n",
        "#expand dimensions to fit 4D input array\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "X_valid = np.expand_dims(X_valid,-1)\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "'''\n",
        "Y_train = to_categorical(Y_train, num_classes=43)\n",
        "Y_test = to_categorical(Y_test, num_classes=43)\n",
        "AdvGAN(X_train, Y_train, X_test, Y_test, batch_size=128, epochs=50, target=3)\n",
        "attack(X_test, Y_test, target=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y shape\n",
            "(34799, 43)\n",
            "y_test shape\n",
            "(12630, 43)\n",
            "t shape)\n",
            "(?, 43)\n",
            "is targeted boolean\n",
            "True\n",
            "WARNING:tensorflow:From <ipython-input-3-5caa55e74d60>:17: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-3-5caa55e74d60>:49: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-5caa55e74d60>:32: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d_transpose instead.\n",
            "(?, 32, 32, 1)\n",
            "WARNING:tensorflow:From <ipython-input-4-85d97f4f431c>:44: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-85d97f4f431c>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "(?, 1)\n",
            "(?, 43)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./weights/target_model/model\n",
            "Pretrained model loaded\n",
            "epoch 1:\n",
            "loss_D: 0.052, loss_G_fake: 0.918,             \n",
            "loss_perturb: 1.636, loss_adv: 4.909, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.021, loss_G_fake: 0.974,             \n",
            "loss_perturb: 0.363, loss_adv: 4.953, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.011, loss_G_fake: 0.982,             \n",
            "loss_perturb: 0.201, loss_adv: 4.927, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.005, loss_G_fake: 0.992,             \n",
            "loss_perturb: 0.022, loss_adv: 4.883, \n",
            "\n",
            "epoch 5:\n",
            "loss_D: 0.003, loss_G_fake: 0.994,             \n",
            "loss_perturb: 0.019, loss_adv: 4.841, \n",
            "\n",
            "epoch 6:\n",
            "loss_D: 0.002, loss_G_fake: 0.995,             \n",
            "loss_perturb: 0.027, loss_adv: 4.827, \n",
            "\n",
            "epoch 7:\n",
            "loss_D: 0.002, loss_G_fake: 0.996,             \n",
            "loss_perturb: 0.028, loss_adv: 4.774, \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
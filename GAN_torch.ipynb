{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_torch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortoisehare/TSR-GAN/blob/master/GAN_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTIpcLONWBq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d65b0eb1-3ce9-4f19-e34f-09c422c1388b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#torch.multiprocessing.set_start_method(\"spawn\") \n",
        "\n",
        "import torch.optim\n",
        "print(torch.__version__)\n",
        "#from torch import np\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')       \n",
        "get_ipython().magic('matplotlib inline')\n",
        "from matplotlib import pyplot    \n",
        "from matplotlib.pyplot import subplot     \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Target Model definition\n",
        "class target_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(target_net, self).__init__()\n",
        "        #input is 32x32\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Convolution\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2, stride=2) \n",
        "        # Fully connected layer\n",
        "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
        "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
        "        self.fc3 = torch.nn.Linear(84, 43)        # convert matrix with 84 features to a matrix of 43 features (columns)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.conv1(x))  \n",
        "        # max-pooling with 2x2 grid \n",
        "        x = self.max_pool_1(x) \n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        # max-pooling with 2x2 grid\n",
        "        x = self.max_pool_2(x)\n",
        "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
        "        # read through https://stackoverflow.com/a/42482819/7551231\n",
        "        \n",
        "        x = x.view(-1, 16*5*5)\n",
        "        # FC-1, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        # FC-2, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        # FC-3\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # MNIST: 1*32x32\n",
        "        model = [\n",
        "            nn.Conv2d(image_nc, 8, kernel_size=4, stride=2, padding=0, bias=True),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 8*16*16\n",
        "            nn.Conv2d(8, 16, kernel_size=4, stride=2, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 16*5*5\n",
        "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "            # 32*1*1\n",
        "        ]\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x).squeeze()\n",
        "        return output\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 gen_input_nc,\n",
        "                 image_nc,\n",
        "                 ):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        encoder_lis = [\n",
        "            # MNIST:1*32x32\n",
        "            nn.Conv2d(gen_input_nc, 8, kernel_size=3, stride=1, padding=0, bias=True),\n",
        "            nn.InstanceNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            # 8*26*26\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=0, bias=True),\n",
        "            nn.InstanceNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            # 16*12*12\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=True),\n",
        "            nn.InstanceNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            # 32*5*5\n",
        "        ]\n",
        "\n",
        "        bottle_neck_lis = [ResnetBlock(32),\n",
        "                       ResnetBlock(32),\n",
        "                       ResnetBlock(32),\n",
        "                       ResnetBlock(32),]\n",
        "\n",
        "        decoder_lis = [\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=0, bias=False),\n",
        "            nn.InstanceNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            # state size. 16 x 11 x 11\n",
        "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=0, bias=False),\n",
        "            nn.InstanceNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            # state size. 8 x 23 x 23\n",
        "            nn.ConvTranspose2d(8, image_nc, kernel_size=6, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. image_nc x 32 x 32\n",
        "        ]\n",
        "\n",
        "        self.encoder = nn.Sequential(*encoder_lis)\n",
        "        self.bottle_neck = nn.Sequential(*bottle_neck_lis)\n",
        "        self.decoder = nn.Sequential(*decoder_lis)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.bottle_neck(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define a resnet block\n",
        "# modified from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, padding_type='reflect', norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=False):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        conv_block = []\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim),\n",
        "                       nn.ReLU(True)]\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_block(x)\n",
        "        return out\n",
        "    \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBB4luoDK1ZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5102660f-a9a3-4e6d-eed8-ed387831de94"
      },
      "source": [
        "#Data loading and preprocessing\n",
        "\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "training_file = 'train.p'\n",
        "testing_file = 'test.p'\n",
        "validation_file = 'valid.p'\n",
        "\n",
        "with open(training_file, mode='rb') as f:\n",
        "    tstrain = pickle.load(f)\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    tstest = pickle.load(f)\n",
        "with open(validation_file, mode='rb') as f:\n",
        "    tsvalid = pickle.load(f)\n",
        "\n",
        "X_train, Y_train = tstrain['features'], tstrain['labels']\n",
        "X_valid, Y_valid = tsvalid['features'], tsvalid['labels']\n",
        "X_test, Y_test = tstest['features'], tstest['labels']\n",
        "\n",
        "#shuffle training set\n",
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=33)\n",
        "X_test, Y_test = shuffle(X_test, Y_test, random_state=33)\n",
        "X_valid, Y_valid = shuffle(X_valid, Y_valid, random_state=33)\n",
        "\n",
        "#grayscale images\n",
        "grayscale = [0.299,0.587,0.144]\n",
        "\n",
        "X_test = np.dot(X_test, grayscale)\n",
        "X_train = np.dot(X_train, grayscale)\n",
        "X_valid = np.dot(X_valid, grayscale)\n",
        "\n",
        "\n",
        "#normalize\n",
        "X_train = np.array(X_train)/255\n",
        "X_test = np.array(X_test)/255\n",
        "X_valid = np.array(X_valid)/255\n",
        "\n",
        "#expand dimensions to fit 4D input array\n",
        "X_train = np.expand_dims(X_train,-1)\n",
        "X_test = np.expand_dims(X_test,-1)\n",
        "X_valid = np.expand_dims(X_valid,-1)\n",
        "\n",
        "X_train = np.transpose(X_train, (0,3,1,2))\n",
        "X_test = np.transpose(X_test, (0,3,1,2))\n",
        "X_valid = np.transpose(X_valid, (0,3,1,2))\n",
        "\n",
        "assert(len(X_train)==len(Y_train))\n",
        "n_train = len(X_train)\n",
        "assert(len(X_test)==len(Y_test))\n",
        "n_test = len(X_test)\n",
        "\n",
        "#Y_train = Y_train.reshape(Y_train.shape[0],1)\n",
        "#Y_test = Y_test.reshape(Y_test.shape[0],1)\n",
        "#Y_valid = Y_valid.reshape(Y_valid.shape[0],1)\n",
        "Y_train = to_categorical(Y_train, num_classes=43)\n",
        "Y_test = to_categorical(Y_test, num_classes=43)\n",
        "Y_valid = to_categorical(Y_valid, num_classes=43)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "print(X_valid.shape)\n",
        "print(Y_valid.shape)\n",
        "\n",
        "train_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
        "train_y = torch.stack([torch.LongTensor(i) for i in Y_train])\n",
        "\n",
        "test_x = torch.stack([torch.Tensor(i) for i in X_test])\n",
        "test_y = torch.stack([torch.LongTensor(i) for i in Y_test])\n",
        "\n",
        "valid_x = torch.stack([torch.Tensor(i) for i in X_valid])\n",
        "valid_y = torch.stack([torch.LongTensor(i) for i in Y_valid])\n",
        "\n",
        "train_dataset = TensorDataset(train_x,train_y)\n",
        "test_dataset = TensorDataset(test_x,test_y)\n",
        "valid_dataset = TensorDataset(valid_x,valid_y)\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(34799, 1, 32, 32)\n",
            "(34799, 43)\n",
            "(12630, 1, 32, 32)\n",
            "(12630, 43)\n",
            "(4410, 1, 32, 32)\n",
            "(4410, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90W2JBoXVrZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "39555243-2c2c-451d-e1c9-d74267c0182b"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "#from models import  MNIST_target_net\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    use_cuda = True\n",
        "    image_nc = 1 #number of channels\n",
        "    batch_size = 128\n",
        "\n",
        "    # Define what device we are using\n",
        "    print(\"CUDA Available: \", torch.cuda.is_available())\n",
        "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "    \n",
        "    #Training set\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, \n",
        "                                  batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "\n",
        "\n",
        "    # training the target model\n",
        "    target_model = target_net().to(device)\n",
        "    target_model.train()\n",
        "    opt_model = torch.optim.Adam(target_model.parameters(), lr=0.001)\n",
        "    epochs = 40\n",
        "    for epoch in range(epochs):\n",
        "        loss_epoch = 0\n",
        "        if epoch == 20:\n",
        "            opt_model = torch.optim.Adam(target_model.parameters(), lr=0.0001)\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            train_imgs, train_labels = data\n",
        "            train_imgs, train_labels = train_imgs.to(device), train_labels.to(device)\n",
        "            logits_model = target_model(train_imgs)\n",
        "            loss_model = F.cross_entropy(logits_model, torch.max(train_labels,1)[1])\n",
        "            loss_epoch += loss_model\n",
        "            opt_model.zero_grad()\n",
        "            loss_model.backward()\n",
        "            opt_model.step()\n",
        "\n",
        "        print('loss in epoch %d: %f' % (epoch, loss_epoch.item()))\n",
        "\n",
        "    # save model\n",
        "    targeted_model_file_name = './target_model.pth'\n",
        "    torch.save(target_model.state_dict(), targeted_model_file_name)\n",
        "    target_model.eval()\n",
        "\n",
        "    # TESTING\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, \n",
        "                                 shuffle=False, num_workers=1)\n",
        "    \n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "        test_img, test_label = data\n",
        "        test_img, test_label = test_img.to(device), test_label.to(device)\n",
        "        test_label = torch.argmax(test_label,1)\n",
        "        pred_lab = torch.argmax(target_model(test_img), 1)\n",
        "        num_correct += torch.sum(pred_lab==test_label,0)\n",
        "\n",
        "    print('accuracy in testing set: %f\\n'%(num_correct.item()/len(test_dataset)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n",
            "loss in epoch 0: 867.171936\n",
            "loss in epoch 1: 329.908875\n",
            "loss in epoch 2: 180.469040\n",
            "loss in epoch 3: 122.758774\n",
            "loss in epoch 4: 92.144035\n",
            "loss in epoch 5: 73.401718\n",
            "loss in epoch 6: 60.132336\n",
            "loss in epoch 7: 49.997833\n",
            "loss in epoch 8: 42.123684\n",
            "loss in epoch 9: 35.821289\n",
            "loss in epoch 10: 30.493837\n",
            "loss in epoch 11: 26.188709\n",
            "loss in epoch 12: 23.320751\n",
            "loss in epoch 13: 21.370928\n",
            "loss in epoch 14: 18.751961\n",
            "loss in epoch 15: 17.185440\n",
            "loss in epoch 16: 15.426431\n",
            "loss in epoch 17: 13.388866\n",
            "loss in epoch 18: 12.575309\n",
            "loss in epoch 19: 11.570383\n",
            "loss in epoch 20: 6.298809\n",
            "loss in epoch 21: 4.877331\n",
            "loss in epoch 22: 4.357321\n",
            "loss in epoch 23: 4.028582\n",
            "loss in epoch 24: 3.770834\n",
            "loss in epoch 25: 3.545673\n",
            "loss in epoch 26: 3.343202\n",
            "loss in epoch 27: 3.156600\n",
            "loss in epoch 28: 2.984880\n",
            "loss in epoch 29: 2.825441\n",
            "loss in epoch 30: 2.673834\n",
            "loss in epoch 31: 2.534400\n",
            "loss in epoch 32: 2.391207\n",
            "loss in epoch 33: 2.257671\n",
            "loss in epoch 34: 2.133803\n",
            "loss in epoch 35: 2.014949\n",
            "loss in epoch 36: 1.910170\n",
            "loss in epoch 37: 1.801654\n",
            "loss in epoch 38: 1.699377\n",
            "loss in epoch 39: 1.603965\n",
            "accuracy in testing set: 0.898100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1FSu-q8WRLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os\n",
        "\n",
        "#models_path = './models/'\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "class AdvGAN_Attack:\n",
        "    def __init__(self,\n",
        "                 device,\n",
        "                 model,\n",
        "                 model_num_labels,\n",
        "                 image_nc,\n",
        "                 box_min,\n",
        "                 box_max):\n",
        "        output_nc = image_nc\n",
        "        self.device = device\n",
        "        self.model_num_labels = model_num_labels\n",
        "        self.model = model\n",
        "        self.input_nc = image_nc\n",
        "        self.output_nc = output_nc\n",
        "        self.box_min = box_min\n",
        "        self.box_max = box_max\n",
        "\n",
        "        self.gen_input_nc = image_nc\n",
        "        self.netG = Generator(self.gen_input_nc, image_nc).to(device)\n",
        "        self.netDisc = Discriminator(image_nc).to(device)\n",
        "\n",
        "        # initialize all weights\n",
        "        self.netG.apply(weights_init)\n",
        "        self.netDisc.apply(weights_init)\n",
        "\n",
        "        # initialize optimizers\n",
        "        self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n",
        "                                            lr=0.001)\n",
        "        self.optimizer_D = torch.optim.Adam(self.netDisc.parameters(),\n",
        "                                            lr=0.001)\n",
        "        models_path = \"./models\"\n",
        "        if not os.path.exists(models_path):\n",
        "            os.makedirs(models_path)\n",
        "\n",
        "    def train_batch(self, x, labels):\n",
        "        # optimize D\n",
        "        for i in range(1):\n",
        "            perturbation = self.netG(x)\n",
        "\n",
        "            # add a clipping trick\n",
        "            adv_images = torch.clamp(perturbation, -0.3, 0.3) + x\n",
        "            adv_images = torch.clamp(adv_images, self.box_min, self.box_max)\n",
        "\n",
        "            self.optimizer_D.zero_grad()\n",
        "            pred_real = self.netDisc(x)\n",
        "            loss_D_real = F.mse_loss(pred_real, torch.ones_like(pred_real, device=self.device))\n",
        "            loss_D_real.backward()\n",
        "\n",
        "            pred_fake = self.netDisc(adv_images.detach())\n",
        "            loss_D_fake = F.mse_loss(pred_fake, torch.zeros_like(pred_fake, device=self.device))\n",
        "            loss_D_fake.backward()\n",
        "            loss_D_GAN = loss_D_fake + loss_D_real\n",
        "            self.optimizer_D.step()\n",
        "\n",
        "        # optimize G\n",
        "        for i in range(1):\n",
        "            self.optimizer_G.zero_grad()\n",
        "\n",
        "            # cal G's loss in GAN\n",
        "            pred_fake = self.netDisc(adv_images)\n",
        "            loss_G_fake = F.mse_loss(pred_fake, torch.ones_like(pred_fake, device=self.device))\n",
        "            loss_G_fake.backward(retain_graph=True)\n",
        "\n",
        "            # calculate perturbation norm\n",
        "            C = 0.1\n",
        "            loss_perturb = torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1))\n",
        "            # loss_perturb = torch.max(loss_perturb - C, torch.zeros(1, device=self.device))\n",
        "\n",
        "            # cal adv loss\n",
        "            logits_model = self.model(adv_images)\n",
        "            probs_model = F.softmax(logits_model, dim=1)\n",
        "            onehot_labels = torch.eye(self.model_num_labels, device=self.device)[labels]\n",
        "\n",
        "            # C&W loss function\n",
        "            \n",
        "            real = torch.sum(onehot_labels * probs_model, dim=1)\n",
        "            other, _ = torch.max((1 - onehot_labels) * probs_model - onehot_labels * 10000, dim=1)\n",
        "            zeros = torch.zeros_like(other)\n",
        "            loss_adv = torch.max(real - other, zeros)\n",
        "            loss_adv = torch.sum(loss_adv)\n",
        "\n",
        "            # maximize cross_entropy loss\n",
        "            # loss_adv = -F.mse_loss(logits_model, onehot_labels)\n",
        "            # loss_adv = - F.cross_entropy(logits_model, labels)\n",
        "\n",
        "            adv_lambda = 10\n",
        "            pert_lambda = 1\n",
        "            loss_G = adv_lambda * loss_adv + pert_lambda * loss_perturb\n",
        "            loss_G.backward()\n",
        "            self.optimizer_G.step()\n",
        "\n",
        "        return loss_D_GAN.item(), loss_G_fake.item(), loss_perturb.item(), loss_adv.item()\n",
        "\n",
        "    def train(self, train_dataloader, epochs):\n",
        "        for epoch in range(1, epochs+1):\n",
        "\n",
        "            if epoch == 50:\n",
        "                self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n",
        "                                                    lr=0.0001)\n",
        "                self.optimizer_D = torch.optim.Adam(self.netDisc.parameters(),\n",
        "                                                    lr=0.0001)\n",
        "            if epoch == 80:\n",
        "                self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n",
        "                                                    lr=0.00001)\n",
        "                self.optimizer_D = torch.optim.Adam(self.netDisc.parameters(),\n",
        "                                                    lr=0.00001)\n",
        "            loss_D_sum = 0\n",
        "            loss_G_fake_sum = 0\n",
        "            loss_perturb_sum = 0\n",
        "            loss_adv_sum = 0\n",
        "            for i, data in enumerate(train_dataloader, start=0):\n",
        "                images, labels = data\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                loss_D_batch, loss_G_fake_batch, loss_perturb_batch, loss_adv_batch = \\\n",
        "                    self.train_batch(images, labels)\n",
        "                loss_D_sum += loss_D_batch\n",
        "                loss_G_fake_sum += loss_G_fake_batch\n",
        "                loss_perturb_sum += loss_perturb_batch\n",
        "                loss_adv_sum += loss_adv_batch\n",
        "\n",
        "            # print statistics\n",
        "            num_batch = len(train_dataloader)\n",
        "            print(\"epoch %d:\\nloss_D: %.3f, loss_G_fake: %.3f,\\\n",
        "             \\nloss_perturb: %.3f, loss_adv: %.3f, \\n\" %\n",
        "                  (epoch, loss_D_sum/num_batch, loss_G_fake_sum/num_batch,\n",
        "                   loss_perturb_sum/num_batch, loss_adv_sum/num_batch))\n",
        "\n",
        "            # save generator\n",
        "            if epoch%20==0:\n",
        "                netG_file_name = models_path + 'netG_epoch_' + str(epoch) + '.pth'\n",
        "                torch.save(self.netG.state_dict(), netG_file_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jw6eaS3WMlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "d8e8b391-4294-4806-905e-c1256df287a0"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "use_cuda=True\n",
        "image_nc=1\n",
        "epochs = 60\n",
        "batch_size = 128\n",
        "BOX_MIN = 0\n",
        "BOX_MAX = 1\n",
        "\n",
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "pretrained_model = \"./target_model.pth\"\n",
        "targeted_model = target_net().to(device)\n",
        "targeted_model.load_state_dict(torch.load(pretrained_model))\n",
        "targeted_model.eval()\n",
        "model_num_labels = 43\n",
        "\n",
        "# train dataset and dataloader declaration\n",
        "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "advGAN = AdvGAN_Attack(device,\n",
        "                          targeted_model,\n",
        "                          model_num_labels,\n",
        "                          image_nc,\n",
        "                          BOX_MIN,\n",
        "                          BOX_MAX)\n",
        "\n",
        "advGAN.train(dataloader, epochs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c92de0aa5823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                           BOX_MAX)\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0madvGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-79729c415c04>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, epochs)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mloss_D_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_G_fake_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_perturb_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_adv_batch\u001b[0m \u001b[0;34m=\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0mloss_D_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_D_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mloss_G_fake_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_G_fake_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-79729c415c04>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# C&W loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprobs_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_labels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: mul(): argument 'other' (position 1) must be Tensor, not torch.return_types.max"
          ]
        }
      ]
    }
  ]
}